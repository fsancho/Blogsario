     <meta charset="utf-8" emacsmode="-*- markdown -*-" lang="es">
	 <!-- <link rel="stylesheet" href="markdeep-docs.css?">-->
	 <link rel="stylesheet" href="latex.css?">
	 
    **Inteligencia Artificial: una ciencia empírica**
    Herbert A. Simon
	Department of Psychology, Carnegie Mellon University, Pittsburgh, PA 15213-3890, USA
	Artificial Intelligence 77 (1995) 95-127


!!!note:Resumen
   Mis objetivos principales en este artículo son, en primer lugar, delimitar las fronteras de la inteligencia artificial y, a continuación, justificar el hecho de llamarla ciencia: ¿es la IA ciencia, o es ingeniería, o alguna combinación de ambas? Después de argumentar que es (al menos) una ciencia, consideraré cuál es la mejor manera de llevarla a cabo: en particular, los papeles respectivos de la experimentación y la teoría en el desarrollo de la IA. Me basaré más en la historia que en la especulación, ya que nuestra experiencia real en el avance del campo tiene mucho que decirnos sobre cómo podemos continuar y acelerar ese avance. Muchos de mis ejemplos se basarán en trabajos con los que he estado asociado, ya que puedo hablar con mayor confianza sobre lo que motivó ese trabajo y sus métodos (y sobre sus defectos) que sobre el trabajo de otros. Mi objetivo, sin embargo, no es hacer un viaje a través de la historia, sino hacer propuestas concretas sobre nuestras prioridades futuras, utilizando la historia, cuando sea pertinente, como prueba de mis puntos de vista.

# IA como ciencia
La IA se ocupa de algunos de los fenómenos que rodean a los ordenadores, por lo que forma parte de la informática [27]. También forma parte de la psicología y la ciencia cognitiva. Se ocupa, en particular, de los fenómenos que aparecen cuando los ordenadores realizan tareas que, si fueran realizadas por personas, se consideraría que requieren inteligencia (pensamiento).

La Inteligencia Artificial comenzó en la década de 1950 como una investigación sobre la naturaleza de la inteligencia. Utilizó los ordenadores como una herramienta revolucionaria para simular, e incluso exhibir, la inteligencia, proporcionando así un medio para examinarla con el máximo detalle. Antes de los ordenadores, los únicos ejemplos observables de inteligencia eran las mentes de los organismos vivos, especialmente los seres humanos. Ahora, a la familia de los sistemas inteligentes se ha unido un nuevo género, los programas informáticos inteligentes.

## Los múltiples objetivos de la IA

Tal y como revelan los artículos publicados en el clásico de Feigenbaum y Feldman, *[Computers and Thought](https://mitpress.mit.edu/books/computers-and-thought-1)*, el objetivo de la IA, desde sus inicios, tenía al menos tres vertientes. Uno de los objetivos era construir programas informáticos (por ejemplo, el *[Logic Theorist](https://es.wikipedia.org/wiki/Logic_Theorist)*) capaces de mostrar inteligencia y, por tanto, empezar a construir una teoría de los sistemas inteligentes. (El nombre original de Carnegie-Rand para este esfuerzo era *procesamiento de información compleja*; nuestro grupo aceptó más tarde la alternativa *Inteligencia Artificial*, que se había convertido en el uso establecido entre los amigos y los enemigos de la actividad).

Un segundo objetivo era construir programas (por ejemplo, *GPS*, *[General Problem Solver](https://es.wikipedia.org/wiki/General_Problem_Solver)*) que mostraran inteligencia utilizando procesos como los que utilizan los humanos en las mismas tareas. En este caso, el objetivo era lograr una teoría de cómo la mente humana puede comportarse de forma inteligente. 

El tercer objetivo era construir programas inteligentes (por ejemplo, el programa de balanceado de la cadena de montaje de Tonge) que pudieran suplir o complementar la inteligencia humana en la realización de algunas de las tareas del mundo. (En el cuerpo de este documento, me referiré a los sistemas de esta tercera categoría como *Sistemas Expertos*, ampliando un poco la denominación habitual de ese nombre). 

Los sistemas descritos en las Secciones 2 y 3 de la Parte 1 de *Computers and Thought* se centran en el primero de estos tres objetivos; los descritos en la Parte 2, en el segundo; y los de las Secciones 4-6 de la Parte 1, en el tercero.

Así pues, casi desde su nacimiento, la IA fue un organismo multicelular. Su base era la capacidad de construir sistemas que exhibieran inteligencia, ya sea como exploraciones puras de la naturaleza de la inteligencia, exploraciones de la teoría de la inteligencia humana o exploraciones de los sistemas que podían realizar tareas prácticas que requerían inteligencia. Alrededor de estos sistemas operativos de IA fueron surgiendo los correspondientes cuerpos teóricos. Pero no debemos pensar en los programas como algo aislado de las teorías. Todo lo contrario. Por ejemplo, *Logic Theorist* encarna una teoría: la teoría de que el logro de la inteligencia en la resolución de problemas requiere un sistema de símbolos físicos capaz de realizar una búsqueda heurística. Asimismo, *GPS* encarna la teoría de que el *[análisis means-ends](https://en.wikipedia.org/wiki/Means%E2%80%93ends_analysis)* es una poderosa heurística empleada habitualmente por las personas para la búsqueda en la resolución de problemas.

Podemos extraer de estos programas declaraciones verbales de los principios teóricos, como hicimos [Allen Newell](https://es.wikipedia.org/wiki/Allen_Newell) y yo en nuestro discurso del [Premio Turing](https://es.wikipedia.org/wiki/Premio_Turing) de 1975, pero además los programas proporcionan las definiciones operativas básicas de lo que significan los principios. La teoría no es más separable del programa que la mecánica clásica de las matemáticas de las leyes del movimiento. Las diferentes implementaciones de los enunciados verbales son teorías diferentes, que muestran propiedades diferentes cuando se ejecutan los programas. Más adelante hablaré de la relación de los programas con las teorías y de cómo se utilizan las ejecuciones de los programas para probar las teorías. Por el momento, me limitaré a recordar que:

!!!quote
   El momento de la verdad es un programa en ejecución.

## La fragmentación social de la IA

Paralelamente al crecimiento de los programas que persiguen el triple objetivo de comprender la inteligencia, entender la mente humana y construir y comprender los sistemas expertos, han surgido comunidades de investigadores preocupados por estos objetivos. Algunos de los investigadores están interesados en más de uno de los tres objetivos, algunos en los tres; pero se han formado estructuras sociales que enfatizan y refuerzan la separación de los tres esfuerzos en lugar de sus preocupaciones comunes.

No describiré estas estructuras sociales en detalle, excepto para mencionar que, de hecho, hay cuatro, no tres, grupos principales; ya que al menos dos grupos bastante distintos de investigadores se centran en la teoría *pura* de la inteligencia. Un subgrupo, que se encuentra principalmente en los departamentos de ciencias de la computación, se asocia a menudo con colegas interesados en la verificación de programas y/o la complejidad computacional. Otro subgrupo se identifica con la *ciencia cognitiva*; algunos de sus miembros se encuentran en Psicología, otros en los grupos de IA de informática, otros en Filosofía, otros en Lingüística, otros en Antropología y en otras áreas diversas.

A lo largo de los años, la distancia que separa a los cuatro grupos de IA ha aumentado gradualmente. Asisten a diferentes reuniones profesionales, que van desde la *Sociedad Americana de Psicología*, pasando por la *Sociedad de Ciencias Cognitivas*, la *AAAI*, hasta la *ACM* y sociedades de ingeniería como el *IEEE*. Limitan cada vez más sus lecturas y citas a las revistas publicadas por sus grupos. Reciben su formación en diferentes disciplinas y subdisciplinas académicas, y cada una de ellas transmite a la siguiente generación su propia versión especializada del problema.

Al asignar una definición amplia a la IA, que abarque a todos estos grupos, revelo mi creencia de que, a pesar de la diversidad de objetivos, existe un núcleo común que hace muy deseable la comunicación continua entre ellos. Creo que cada uno de estos grupos puede obtener una ayuda sustancial para avanzar en sus objetivos aprovechando el trabajo de los demás, y que las ventajas de la interacción (y las graves desventajas de la fragmentación) se han demostrado con frecuencia a lo largo de toda la historia de la IA. Creo que la AAAI y la Sociedad de Ciencias Cognitivas comparten la responsabilidad principal de oponerse y hacer retroceder a las fuerzas de  disociación.

Mis razones para creer en la complementariedad de los distintos objetivos surgirán a medida que avance. Me gustaría exponer ahora dos de las razones, de forma preliminar.

En primer lugar, la forma en que los humanos logran la inteligencia (la llamaré **búsqueda heurística**) es bastante diferente de la forma en que los ordenadores que realizan análisis numéricos y tareas similares suelen hacerlo (podríamos llamar a este último método **fuerza bruta disciplinada por las matemáticas**). La distinción no es blanca o negra, pero es obvia. Los métodos humanos, en mi opinión, son absolutamente esenciales para dar una respuesta inteligente a problemas relativamente mal estructurados, de ahí que debamos comprenderlos independientemente de que nuestro objetivo sea entender la mente humana o la inteligencia en general.

Los programas para resolver problemas de programación lineal, invertir matrices o resolver ecuaciones diferenciales parciales dependen en gran medida del tamaño y la velocidad de los ordenadores, pero utilizan algoritmos basados en estructuras matemáticas conocidas, y normalmente ricas, de sus espacios de problemas para reducir la cantidad de búsqueda necesaria. Estos principios de reducción de la búsqueda no siempre optimizan la búsqueda, pero casi siempre preservan la propiedad de completitud: garantizan la búsqueda de la solución con cualquier grado de aproximación deseado. Debido a la regularidad matemática de los espacios de búsqueda, a menudo es posible demostrar teoremas sobre la suficiencia, y a veces la eficiencia, de los algoritmos.

La resolución de problemas por parte de los humanos rara vez comparte alguna de estas propiedades. Sin embargo, los seres humanos, cuyas capacidades de cálculo son insignificantes en comparación con las de los superordenadores modernos o incluso los ordenadores personales, a veces son capaces de resolver, con poco cálculo, problemas que son muy difíciles incluso para los estándares informáticos: problemas con objetivos mal definidos, espacios de problemas mal caracterizados y acotados, falta de estructura matemática sólida y regular. La gente resuelve estos problemas mediante el uso astuto de la heurística y a costa de renunciar a la garantía de integridad de la búsqueda y a la optimización de las soluciones alcanzadas.

Lo que yo llamo **fuerza bruta disciplinada** tuvo su origen en el Análisis Numérico y en su sucesora, la Teoría de la Computación, que ha tenido cierta extensión de los sistemas numéricos a los simbólicos. Muchos de nosotros no creemos que los métodos de fuerza bruta disciplinada puedan alcanzar el mismo rango de aplicación y flexibilidad que los humanos. A menos que se demuestre que sí pueden, tenemos todas las razones para explorar vigorosamente las técnicas de búsqueda heurística humana como fuente de ideas para los sistemas inteligentes, e igual razón para entender los mecanismos subyacentes que dan a estas técnicas su poder en situaciones en las que la fuerza bruta, incluso la fuerza bruta disciplinada, falla. Estas preocupaciones son fundamentales tanto para entender cómo la inteligencia, humana o no, puede aplicarse a problemas mal estructurados, como para construir sistemas expertos para resolver dichos problemas.

La Inteligencia Artificial siempre ha tenido un interés especial en este importante ámbito *residual*, en el que los programas se basan en la búsqueda heurística, sin garantías de exhaustividad, y a menudo utilizan criterios de éxito satisfactorios. Dado este interés, tienen todas las razones para mantenerse en estrecho contacto con los progresos de la investigación en inteligencia humana, que está desmitificando gradualmente la naturaleza de la *astucia*, la *intuición* e incluso la *creatividad* humanas.

Una segunda razón para mantener una estrecha comunicación entre todas las subdivisiones de la IA es que el principal medio de progreso en nuestro campo es encontrar tareas que requieran inteligencia para su realización, y luego ver qué tipos de procesos son suficientes para realizar estas tareas. A lo largo de los años, la exploración de un dominio cada vez más amplio de tareas ha revelado una gama cada vez más rica de mecanismos de comportamiento inteligente. Y como ilustra la gran diversidad de programas informáticos existentes que juegan al ajedrez, incluso para una sola tarea puede haber muchas formas de pelar el gato. La comparación de programas alternativos puede arrojar mucha luz sobre los principios subyacentes de la inteligencia. El comportamiento humano proporciona una valiosa gama de difíciles tareas mal estructuradas en las que se exhiben regularmente las características peculiares de la inteligencia humana.

# Objetos artificiales y naturales

Los objetos artificiales, incluidos los programas de ordenador, son lo que son porque fueron diseñados para ser así. Este hecho ha llevado a algunos a afirmar que no puede haber una ciencia de los objetos artificiales, sino sólo una tecnología de ingeniería. Los que defienden la forma más extrema de este punto de vista consideran que el descubrimiento y la demostración de teoremas matemáticos sobre los sistemas inteligentes es la única vía genuina hacia una ciencia de la IA, y denigran el papel de la construcción de sistemas y la experimentación como *sólo ingeniería*.

Pero la afirmación de que los objetos artificiales están divorciados de la ciencia empírica y que no se prestan a los métodos de investigación de la ciencia natural es falaz. Un objeto artificial está tan sujeto a las leyes de la naturaleza como cualquier objeto natural. Los automóviles están tan sujetos a la ley de la gravedad y la conservación de la energía como los glaciares. Las leyes científicas limitan el conjunto de objetos posibles, naturales o artificiales. No existe ningún objeto, artificial o natural, que no obedezca estas leyes, que no satisfaga estas limitaciones [36, capítulo 1].

## Restricciones internas

Las leyes naturales que determinan la estructura y el comportamiento de un objeto, natural o artificial, son sus restricciones internas. Un sistema artificial, al igual que uno natural, produce fenómenos empíricos que pueden ser estudiados por los métodos de observación y experimentación comunes a toda ciencia.

Se podría objetar que un sistema diseñado deliberadamente para comportarse de una manera deseada no puede producir ninguna sorpresa o información nueva. Esta objeción hace caso omiso de nuestra enorme ignorancia de la ley natural y de los efectos producidos por las leyes naturales que operan en los sistemas complejos. El mundo de los objetos artificiales (y naturales) está lleno de consecuencias imprevistas, debido a los límites tanto del conocimiento empírico como de la potencia de cálculo. El caso, en la IA, de estudiar empíricamente muchos tipos diferentes de sistemas es esencialmente idéntico al caso, en biología, de estudiar muchas especies de organismos. En ninguno de los dos casos podemos captar más que una parte minúscula de la riqueza y la complejidad del mundo real intentando deducirlo a partir de los primeros principios.

A menudo, la forma más eficaz de predecir y comprender el comportamiento de un nuevo sistema complejo es construir el sistema y observarlo. Como los programas de IA también son modelos computacionales, podemos utilizar los propios programas como sus propios modelos, una ventaja para el campo de la IA que es única en la ciencia. En la IA, la teoría no sólo modela, sino que exhibe simultáneamente el comportamiento de los fenómenos estudiados.

Las ciencias *naturales* también dependen, para su progreso, de la construcción de sistemas artificiales y del estudio de su comportamiento, pues ésta es la esencia del método experimental. El científico natural construye un sistema en el que se cree que destaca el funcionamiento de ciertas leyes naturales; luego observa los fenómenos producidos por el sistema y, sobre todo, cómo cambian estos fenómenos con los cambios en los parámetros del sistema. Así, Galileo hace rodar pelotas por planos inclinados o por encima de los bordes de las mesas, y mide el tiempo del rodaje o la duración del vuelo en función del ángulo del plano.

Experimentar es utilizar lo artificial para estudiar lo natural. Diseñar un sistema de IA y observar cómo cambia su comportamiento con los cambios en el diseño es realizar un experimento. La mayor parte de lo que sabemos sobre la inteligencia artificial se ha aprendido realizando experimentos de este tipo, lo que convierte a la IA en una ciencia completamente experimental.

## Restricciones externas

Un sistema, ya sea artificial o natural, debe ajustarse no sólo a las restricciones internas impuestas por la ley natural, sino también a dos conjuntos de restricciones externas. El sistema sólo puede nacer en condiciones definidas por la ley natural y sólo puede sobrevivir y funcionar eficazmente en entornos adecuados. Estas condiciones iniciales y de contorno son las restricciones externas del sistema. La química sintética -como la IA, una ciencia de diseño- se dedica a determinar (mediante síntesis real) las restricciones externas que operan sobre las moléculas químicas.

Al manipular las restricciones externas, a menudo podemos determinar qué funciones debe realizar un sistema para sobrevivir, y cómo sus diversos componentes llevan a cabo estas funciones. La naturaleza, según Darwin, genera sistemas o modifica los existentes; luego pone a prueba su capacidad para sobrevivir en el entorno. El artífice hace exactamente lo mismo, salvo que el generador (el proceso de diseño) es más intencionado, y las pruebas (los propósitos que el diseñador tiene en mente) pueden ir más allá de la aptitud biológica.

Como los requisitos funcionales impuestos por el entorno introducen un componente teleológico en todos los sistemas del mismo modo que los propósitos del diseñador, la diferencia entre lo natural y lo artificial se desvanece y luego desaparece. Las limitaciones impuestas por la naturaleza a los organismos vivos derivan de las mismas leyes naturales que las que afronta el diseño.

## Ciencia e Ingeniería

Vemos que, lejos de esforzarnos por separar la Ciencia de la Ingeniería, no necesitamos distinguirlas en absoluto. Pero si insistimos en una distinción, podemos pensar que la Ingeniería es una Ciencia para gente impaciente. Los procesos darwinianos de la biología dependen del azar de las mutaciones y los cruces para producir nuevos diseños. Aunque también hay un gran elemento de azar en los procesos de diseño humanos, el azar está moderado por la heurística que utiliza el conocimiento previo, lo que ya se sabe sobre los sistemas de interés, para generar y combinar elementos de forma muy selectiva, aumentando enormemente las probabilidades de que el producto sea funcional.

Mientras que al científico le interesa específicamente crear nuevos conocimientos, al ingeniero le interesa también crear sistemas que alcancen los objetivos deseados. Aparte de esta diferencia de motivos, no es necesario distinguir entre informáticos e ingenieros informáticos, o científicos e ingenieros de IA. Podemos dejar de debatir si la IA es Ciencia o Ingeniería; es ambas cosas.

# Investigación por síntesis de sistemas

Es hora de relacionar estas generalidades con la disciplina de la Inteligencia Artificial. Independientemente de las razones que nos lleven a perseguir la IA, su principal método de investigación consiste en construir y estudiar sistemas que muestren inteligencia. El paradigma básico es:

!!!quote
   Seleccionar una tarea que incorpore una característica de inteligencia que tenga una importancia práctica sustancial o que presente características y complejidades que aún no hayan sido simuladas por los sistemas de IA. Construir un sistema que muestre esta característica de inteligencia. Examinar el comportamiento del sistema en diferentes entornos de tareas y con diferentes condiciones iniciales.

*Logic Theorist* incorporó algunos métodos sencillos de búsqueda heurística, que se probaron en la tarea de descubrir pruebas de teoremas. *GPS* incorporó el análisis means-ends, que se probó en una variedad de dominios simples de resolución de problemas. *[SHRDLU](https://es.wikipedia.org/wiki/SHRDLU)* [41] tenía medios para procesar cadenas de lenguaje natural y extraer sus significados semánticos, que se probaron en un mundo de bloques. *[EPAM](https://en.wikipedia.org/wiki/EPAM)* [11] tiene mecanismos para reconocer, recordar y aprender a discriminar, que se probaron en una serie de entornos experimentales extraídos de la literatura de investigación sobre el aprendizaje verbal. *[NAVLAB](https://en.wikipedia.org/wiki/Navlab)* [30] tiene mecanismos para determinar la posición de un vehículo y dirigirlo, que se ponen a prueba conduciéndolo por carreteras. ¿En qué sentido este tipo de proyectos de diseño son experimentos?

## El diseño de sistemas como experimentación

Un experimento manipula las variables independientes y dependientes de un sistema concreto. ¿Cuáles son las variables independientes y dependientes de un sistema de IA? Las variables dependientes son claramente medidas del rendimiento del sistema: cómo se comporta de forma inteligente tanto en términos de la gama de tareas que puede manejar como de su habilidad y eficiencia al manejarlas.

La definición de las variables independientes requiere un poco más de cuidado. Supongamos que estudiamos una versión concreta del *GPS*. En primer lugar, está el núcleo del sistema: en el caso de *GPS*, principalmente sus capacidades básicas de procesamiento de símbolos y su mecanismo de análisis means-ends. De forma un poco más periférica, también contiene estrategias para la búsqueda heurística; puede incorporar la *búsqueda del mejor primero*, por ejemplo, o la *búsqueda de profundidad primero*. De forma aún más periférica, contiene información sobre dominios de tareas particulares, incluyendo producciones que notan diferencias entre situaciones (situación actual y situación objetivo) y producciones que seleccionan operadores de movimiento relevantes para reducir las diferencias que se notan.

Los cambios en cualquiera de estos componentes o en todos ellos pueden considerarse como cambios en las restricciones internas del *GPS*. O bien, podemos pensar en las capacidades de procesamiento de símbolos y en el mecanismo means-ends como restricciones internas, y en los componentes restantes como condiciones iniciales. Tanto las restricciones internas como las condiciones iniciales pueden tratarse como variables independientes a efectos experimentales. Además, los entornos de tareas con los que nos enfrentamos con *GPS* definen las restricciones externas de su comportamiento, constituyendo otro conjunto de variables independientes.

En los primeros experimentos en IA, con sistemas como *LT*, *GPS*, *STUDENT* y los demás que se recogen en *Computers and Thought*, el dominio de la tarea y el conocimiento del dominio se mantenían constantes, mientras que las principales variables independientes eran el núcleo del propio sistema, y a menudo sus estrategias. La pregunta que había que responder era: *¿Qué capacidades simbólicas básicas y heurísticas permitirán a un sistema mostrar inteligencia en un dominio de tarea que es difícil para los humanos?*

Los procedimientos para evaluar los resultados no estaban elaborados. ¿Resolvió el sistema los problemas con un esfuerzo informático moderado? ¿Se comportó de forma selectiva, en comparación con una búsqueda de fuerza bruta? ¿A qué nivel de dificultad del problema podía operar (en comparación, por ejemplo, con las habilidades humanas)?

Hoy en día, cuando un proyecto de inteligencia artificial tiene como objetivo ampliar la IA a una nueva clase de dominios de tareas, las cosas siguen siendo muy parecidas. El sistema *[BACON](http://facweb.cs.depaul.edu/jphillips/Classes/CSD/lecture5.pdf)* [21] para el descubrimiento científico toma un conjunto de datos de un experimento. *BACON* contiene capacidades básicas de manipulación de símbolos y un pequeño conjunto de heurísticas para inducir leyes a partir de los datos e inventar nuevos conceptos teóricos. La experimentación consiste en explorar la gama de tareas sobre las que puede y no puede descubrir las regularidades de los datos, las razones de sus éxitos y fracasos (es decir, la relación entre sus capacidades y las características de los entornos de tareas correspondientes) y el grado de selectividad de su búsqueda.

En una línea de experimentación de este tipo, ya sea con *GPS* o con *BACON*, inicialmente, la principal variable independiente es el núcleo del propio sistema y sus estrategias. ¿Qué cambios en el sistema mejorarán su rendimiento en una tarea, y qué cambios son necesarios para manejar nuevas tareas? A medida que el rendimiento del sistema mejora, el énfasis puede pasar de la manipulación de las características del sistema a la prueba de un sistema fijo en una serie de entornos de tareas. ¿En qué medida es flexible y general el sistema?

Por otro lado, en la investigación dentro del llamado paradigma experto-novato, las condiciones iniciales, es decir, el conocimiento del dominio del sistema, es la variable independiente central. El interés principal es aprender cuánto conocimiento, organizado cómo en la memoria, es necesario para el rendimiento de un experto. En la investigación sobre la generalidad, el dominio de la tarea es la variable independiente central. ¿Existe un pequeño núcleo de mecanismos que pueda soportar la mayor parte de la carga en todas las tareas?

### Ampliabilidad

Dos temas son visibles en gran parte de la experimentación de la IA. Uno es la capacidad de ampliación y el otro la generalidad de las tareas. Las nuevas ideas de la IA se prueban a menudo en *tareas de juguete*, es decir, tareas mejor estructuradas y menos difíciles que las tareas de la vida real que nos gustaría realizar. La *Torre de Hanoi* es una tarea de juguete; el diagnóstico médico es una tarea de la vida real.

El aprendizaje de un lenguaje es una tarea de la vida real, pero podemos construir un sistema de IA, por ejemplo, el *[ZBIE](https://ti.arc.nasa.gov/m/pub-archive/329h/0329%20(Clancey).pdf)* de Siklossy [34], que, si bien ha demostrado su capacidad para adquirir una sintaxis y una semántica sencillas, por una u otra razón aún no está preparado para manejar todo el alcance de un lenguaje natural. Ilustramos una tarea de la vida real simulando una subtarea de juguete.

Podemos considerar a *ZBIE* como una teoría candidata del aprendizaje del lenguaje, pero nuestra confianza en su veracidad dependerá de la perspectiva de ampliar sus capacidades para adquirir un lenguaje natural completo. Si los límites de *ZBIE* parecen deberse al poco tiempo que ha tenido para aprender o a los límites físicos del tamaño de la memoria, seremos más optimistas sobre su capacidad de ampliación que si vemos que se necesitarán mecanismos adicionales o diferentes para la ampliación. Por supuesto, la prueba final de su fuerza como teoría será el intento real de ampliarla.

Debemos recordar que la mayoría de las teorías de la física sólo se ponen a prueba en situaciones de laboratorio relativamente sencillas y, de hecho, muchos fenómenos importantes sólo pueden observarse claramente en condiciones muy controladas. Así que debemos tener cuidado de no imponer en la IA requisitos de verificación de la teoría mucho más fuertes que los impuestos en otras ciencias. Eso garantizaría, sin duda, que nunca llegaríamos a tener creencias sobre nada significativo.

Una buena razón para ser precavidos en cuanto a la escalabilidad ascendente de los programas que manejan con éxito las subtareas de juguete es que en la IA siempre nos enfrentamos al espectro de la explosión combinatoria de la búsqueda. Pero a medida que hemos ido ganando confianza en nuestra capacidad de construir y utilizar grandes bases de conocimiento para aumentar la selectividad en programas como *[DENDRAL](https://es.wikipedia.org/wiki/Dendral)* [23] e *[INTERNIST](https://en.wikipedia.org/wiki/Internist-I)* [31], y a medida que hemos conseguido construir un número cada vez mayor de sistemas que operan a niveles profesionales (humanos) de rendimiento, el espectro se vuelve menos amenazador. Y, como comentaré más adelante, tales advertencias como la **NP**-completitud no amenazan con la explosión combinatoria para la mayoría de los problemas que realmente buscamos resolver.

### Generalidad sobre las tareas

La IA está más interesada, como debe ser, en descubrir aquellos mecanismos de inteligencia que se aplican a una amplia gama de tareas. El *GPS* se diseñó para separar los componentes independientes de la tarea de los componentes dependientes de la tarea del programa, y Ernst y Newell [8] emprendieron una extensa actividad de investigación para demostrar que podía resolver problemas en una docena o más de entornos sin alterar el componente independiente de la tarea del programa. La teoría de resolución de problemas que representa *GPS* es ese componente del programa.

Del mismo modo, el programa *EPAM* [11] contiene un núcleo de mecanismos de reconocimiento, memoria y aprendizaje. Para realizar cualquier tarea dentro de sus capacidades, debe adquirir (o recibir) un cuerpo de conocimientos apropiado, almacenado como condiciones iniciales en su memoria, así como estrategias derivadas de las instrucciones de la tarea. Son principalmente los mecanismos centrales los que consideramos la teoría *EPAM*; y son estos mecanismos los que deberían permanecer invariables a medida que *EPAM* se extiende a nuevas tareas.

Sin embargo, no debe suponerse que el contenido teórico de los programas se limita a sus núcleos. Saber cuánto conocimiento, y qué tipo de conocimiento, requiere un programa para extenderlo a tareas de la vida real es también una parte importante de la teoría de la IA. Hoy en día sería de enorme interés saber qué conocimiento, cómo de organizado, sería necesario para que un programa de ajedrez jugara a nivel de gran maestro sin necesidad de buscar más (¿100 ramas?) que un gran maestro humano.

La investigación dentro del paradigma experto-novato se ha centrado específicamente en determinar las bases de conocimiento necesarias para un rendimiento de alto nivel. La Inteligencia Artificial se ocupa de comprender tanto los procesos heurísticos generales (y otras bases de la inteligencia) que son aplicables a muchos dominios como los procesos más especializados que permiten alcanzar altos niveles de rendimiento en dominios concretos.

## La hipótesis del sistema de símbolos físicos

La primera tarea de la investigación en IA fue determinar si se podía obtener un comportamiento inteligente con sistemas de procesamiento de listas simbólicas. Los repetidos éxitos que el campo alcanzó en una variedad de dominios de tareas nos llevaron a Newell y a mí, en nuestra conferencia Turing de 1976, a ofrecer una hipótesis para explicar esta fuerte base común de toda la gama de dispositivos y programas inteligentes. La llamamos la *Hipótesis del Sistema de Símbolos Físicos*:

!!!quote
   Un sistema de símbolos físicos (PSS) tiene los medios necesarios y suficientes para la acción inteligente general.

Dado que la hipótesis es conocida, no es necesario que recuente en detalle las características que definen a un sistema de símbolos físicos. Un PSS es simplemente un sistema capaz de almacenar símbolos (patrones con denotaciones), y de introducir, emitir, organizar y reorganizar tales símbolos y estructuras de símbolos, comparándolos por identidad o diferencia, y actuando condicionalmente en los resultados de las pruebas de identidad. Se ha demostrado que los ordenadores digitales son PSS, y se ha acumulado un sólido conjunto de pruebas de que los cerebros también lo son. Los materiales físicos de los que están hechos los PSS y las leyes físicas que rigen estos materiales son irrelevantes siempre que soporten el almacenamiento simbólico y la rápida ejecución de los procesos simbólicos mencionados anteriormente.

La hipótesis de los PSS afirma que las restricciones externas impuestas por cualquier tarea que requiera inteligencia pueden ser satisfechas por, y sólo por, un PSS. Dado que las diferentes tareas imponen restricciones muy diferentes, la afirmación de que ser un PSS es necesario y suficiente para la inteligencia puede parecer sorprendente. Su veracidad depende esencialmente de la generalidad y adaptabilidad de los PSS, como los ordenadores y los cerebros. Por supuesto, no estamos hablando de la verdad matemática (por ejemplo, la computabilidad de Turing), sino del hecho empírico de que los ordenadores y los cerebros, adecuadamente instruidos, pueden mostrar inteligencia en una amplia gama de tareas, empleando sólo cantidades aceptables de computación para hacerlo.

Hoy en día existe cierta controversia sobre la Hipótesis del Sistema de Símbolos Físicos, que gira en torno a la definición del término *símbolo*. Si definimos el término *símbolo* de forma restringida, de modo que los componentes básicos de los sistemas conexionistas o los robots del tipo defendido por Brooks no se consideren símbolos, la hipótesis es claramente errónea, ya que los sistemas de este tipo muestran inteligencia. Si definimos los símbolos (como yo lo he hecho, más arriba) como patrones que denotan, entonces los sistemas conexionistas y los robots de Brooks [2] son sistemas de símbolos físicos. En cualquier caso, la hipótesis es empírica, cuyo destino seguirá siendo decidido por la evidencia empírica sobre los mecanismos empleados por los sistemas que exhiben inteligencia, independientemente de dónde tracemos el límite de definición de *símbolo*.

# Teorías de la inteligencia

Dejando a un lado ahora la tarea de diseño de sistemas inteligentes específicos, pasamos a la tarea de desarrollar las teorías de esos sistemas junto con las teorías del proceso de diseño. Debo preceder lo que voy a decir con una discusión sobre lo que significa, o debería significar, el término *Teoría*.

## ¿Qué es una Teoría?

Existe una desafortunada confusión, fomentada por la similitud entre las palabras *Teoría* y *Teorema*, entre las teorías de una ciencia empírica, por un lado, y las teorías deductivas formales, por otro. Esta confusión se originó probablemente con el gran éxito de la *Mecánica Newtoniana* en obtener mucho de poco, y ciertamente ha sido fomentada por ella. A partir de unas pocas premisas básicas, en particular las tres leyes del movimiento, se derivan matemáticamente todo tipo de consecuencias importantes sobre el comportamiento de la materia en el mundo real.

En muchas mentes, este éxito ha creado la ilusión de que la Física es casi una rama de las Matemáticas (recordemos los innumerables libros de texto sobre *Mecánica Racional*); y ha creado fuertes impulsos en las demás ciencias para emular este camino real hacia la verdad empírica mediante el razonamiento. La Economía ofrece quizá los ejemplos más flagrantes del uso de la lógica sin límites de observación para llegar a conclusiones injustificadas sobre el mundo real, pero no faltan ejemplos en las demás ciencias, incluida la Informática.

Muy poco de la física de los sistemas complejos (la atmósfera, el océano, la materia condensada) tiene este sabor altamente deductivo. Las Matemáticas existen, en porciones generosas, pero están rodeadas de condiciones de contorno y condiciones iniciales que se basan en la observación empírica. A veces se olvida que la *[Teoría de la Relatividad Especial](https://es.wikipedia.org/wiki/Teor%C3%ADa_de_la_relatividad_especial)* fue motivada por las anomalías de la observación, especialmente la incompatibilidad entre la invariancia galileana de las [Leyes de la Mecánica](https://es.wikipedia.org/wiki/Mec%C3%A1nica_cl%C3%A1sica) y la invariancia de Lorentz de las *[Leyes de Maxwell](https://es.wikipedia.org/wiki/Ecuaciones_de_Maxwell)*. Del mismo modo, la *[Ley de Planck](https://es.wikipedia.org/wiki/Ley_de_Planck)* sobre la radiación del cuerpo negro fue motivada por el fracaso de la *[Ley de Wien](https://es.wikipedia.org/wiki/Ley_de_desplazamiento_de_Wien)* para explicar las intensidades de las líneas espectrales frente a las nuevas observaciones de la radiación infrarroja obtenidas cuando los bolómetros se extendieron a ese rango espectral. Los fenómenos cuidadosamente observados siguen siendo el punto de partida de la teoría en Física.

Cuando pasamos de la Física a ciencias como la Biología y la Geología, e incluso la Química, la prioridad de los fenómenos observados sobre las conclusiones alcanzadas mediante largas cadenas de inferencia a partir de axiomas generales se hace aún más evidente. No sólo la mayoría de las regularidades conocidas en estas ciencias se derivan de una amplia observación y experimentación, sino que muchas de las regularidades, especialmente las más importantes, no son cuantitativas, sino cualitativas. En nuestro discurso de Turing, Newell y yo llamamos a estas generalizaciones *Leyes de Estructura Cualitativa* (*Leyes QS*). La *Teoría de los Gérmenes de la Enfermedad*, observamos, es una ley cualitativa e inexacta, al igual que la *Teoría de la Célula*, y para el caso, la *Teoría de la Evolución por Selección Natural*. Si hay alguna ecuación en *[El origen de las especies](https://es.wikipedia.org/wiki/El_origen_de_las_especies)*, es muy poco visible.

La *Teoría de los Gérmenes de las Enfermedades* dice algo así como: *Si diagnosticas una enfermedad, busca un microorganismo (por supuesto, no siempre lo encontrarás)*. La *Teoría Celular* dice algo así como: *La mayoría de los organismos están formados por una o más (¡quizá muchas más!) estructuras delimitadas por membranas llamadas 'células' que son notablemente similares entre las especies en cuanto a su estructura básica, por ejemplo, todas tienen núcleo (en realidad, por supuesto, sólo las eucariotas lo tienen).* Ambas teorías son cualitativas, aproximadas, incluso vagas. Estas teorías centrales pronto se rodean de multitud de particularidades, de diversos grados de precisión y generalidad, que describen leyes de organización y proceso. La mayoría de ellas son *leyes QS*, relativamente pocas son cuantitativas.

Cuando se trata de sistemas complejos, sea cual sea la ciencia, las teorías tienen casi todas este tipo de complejidad y desorden. Hasta cierto punto, todavía pueden modelarse matemáticamente, o parte de ellas, si su aplicación se limita a casos sencillos. En el caso de subsistemas aún más pequeños y sencillos, las formulaciones matemáticas pueden resolverse a veces de forma cerrada. Lo más frecuente es que el comportamiento de los sistemas complejos tenga que estudiarse mediante modelización y simulación por ordenador, con poca o ninguna ayuda de los teoremas. Incluso en las partes más teóricas de la Física actual, los problemas rara vez se resuelven de forma simbólica cerrada; lo más frecuente es que se resuelvan numéricamente con muchas horas de cálculo; y los físicos son los mayores usuarios del mundo de los superordenadores.

Debido a estas propiedades de los sistemas complejos, término que describe esencialmente todos los sistemas de IA de interés, nos encontramos con que en IA las principales teorías adoptan dos formas, que a primera vista parecen diametralmente opuestas: hay teorías precisas en forma de programas de ordenador, y teorías más difusas de la forma que Allen Newell y yo denominamos *Leyes de Estructura Cualitativa*. Examinemos cada una de ellas en su aplicación a IA.

## Programas informáticos como teorías en IA

En las Ciencias Físicas, los *Sistemas de Ecuaciones Diferenciales* constituyen la principal herramienta para expresar teorías precisas sobre el comportamiento de los sistemas. Para realizar predicciones en cualquier situación, las ecuaciones diferenciales deben complementarse con estimaciones empíricas de los parámetros del sistema y de las condiciones iniciales y de contorno.

En la Ciencia Cognitiva, los programas de ordenador, que desde un punto de vista formal son simplemente sistemas de ecuaciones diferenciales, desempeñan exactamente el mismo papel que los sistemas de ecuaciones diferenciales en la Física. La única diferencia entre las ecuaciones diferenciales y las ecuaciones en diferencias es que las primeras tratan el tiempo como una variable continua, mientras que las segundas lo tratan como una variable discreta: el sistema cambia de estado en cada ciclo de cálculo. Dado que el intervalo de tiempo básico representado por el sistema puede fijarse en cualquier valor, se trata de una distinción sin importancia. (De hecho, cuando realizamos cálculos numéricos sobre sistemas de ecuaciones diferenciales, rutinariamente aproximamos el tiempo continuo por el discreto).

Los sistemas simples de ecuaciones diferenciales y en diferencias en números reales o complejos pueden resolverse en forma cerrada para obtener teoremas generales del comportamiento del sistema para cualquier valor de los parámetros. Como hemos visto, cuando las cosas se vuelven un poco más complejas, o cuando los símbolos de las ecuaciones no son numéricos, ya no se pueden obtener soluciones en forma cerrada, y el sistema se estudia realizando simulaciones para diversos valores de los parámetros. Como los resultados sólo se aplican a los valores particulares de los parámetros utilizados en las simulaciones, volvemos de nuevo a los tipos de generalizaciones cualitativas que caracterizan a todos los sistemas complejos.

Al interpretar los programas como teorías, debemos tener cuidado de definir qué características de los programas representan la teoría, qué características deben considerarse como *notación* irrelevante y qué partes constituyen condiciones de contorno y condiciones iniciales para una aplicación particular de la teoría. Estas mismas cuestiones se plantean en las teorías de las ciencias naturales, pero quizá adopten una forma particular en la IA que merece la pena examinar.

En la discusión anterior sobre la experimentación, vimos que un programa de IA en funcionamiento contiene una definición del objetivo y conocimientos sobre el dominio de la tarea, así como procesos de resolución de problemas. También contiene estrategias, algunas de las cuales pueden ser específicas de la tarea. Cuando decimos que *GPS* es una teoría de resolución de problemas, estamos hablando del programa central, incluyendo al menos algunas de las estrategias más generales e independientes de la tarea.

Por ejemplo, el programa *EPAM* es una teoría de los procesos perceptivos y de memoria humanos [11]. Para poner a prueba sus predicciones en cualquier situación de tarea, hay que darle los estímulos más el conocimiento relevante que se supone que ya está en la memoria en el momento de realizar la tarea y las estrategias utilizadas por el sujeto para realizarla. Cómo llegó esta información a la memoria y por qué y cómo se adoptaron determinadas estrategias son también objetivos apropiados de la investigación científica, pero no forman parte del núcleo de la teoría *EPAM*.

Si quitamos todo el contenido específico del dominio de *EPAM*, o de un programa de diagnóstico médico o de un programa de juego de ajedrez, lo que queda es normalmente un pequeño conjunto de mecanismos bastante simples. Del mismo modo, *BACON* [21], que es capaz de descubrir leyes científicas y nuevos conceptos teóricos para una amplia gama de fenómenos físicos y químicos, consiste en una media docena de heurísticas independientes del dominio para generar hipótesis para su consideración, y una simple heurística de control de búsqueda.

### Teoría frente a detalles de programación

En las Ciencias Naturales, suele haber relativamente poca confusión entre la teoría y la notación en la que se expresa. Las *Ecuaciones de Maxwell* pueden escribirse en la anticuada notación de coordenadas o en la más moderna notación vectorial. Todo el mundo está de acuerdo en que en cualquiera de las dos formas se trata de la misma teoría. Incluso en un caso más complejo y sutil, todo el mundo está de acuerdo en que las *[Matrices de Heisenberg](https://es.wikipedia.org/wiki/Mec%C3%A1nica_matricial)*, las *[Ecuaciones de Onda de Schrödinger](https://es.wikipedia.org/wiki/Ecuaci%C3%B3n_de_Schr%C3%B6dinger)* y la *[Formulación Algebraica Abstracta de Dirac](https://es.wikipedia.org/wiki/Ecuaci%C3%B3n_de_Dirac)* representan la misma teoría: la *[Mecánica Cuántica](https://es.wikipedia.org/wiki/Mec%C3%A1nica_cu%C3%A1ntica)*.

En las teorías implementadas mediante la ejecución de programas, sigue habiendo cierta ambigüedad en cuanto a la jerarquía de los formalismos de programación a la que se extiende la teoría. Está claro que el hecho de que un programa esté escrito en *[Common Lisp](https://es.wikipedia.org/wiki/Common_Lisp)* no forma parte de la teoría que expresa. ¿Pero qué hay del hecho de que esté escrito en alguna forma de *Lisp*? ¿O que esté escrito en un lenguaje de procesamiento de listas y no en un lenguaje algebraico? Dado que la velocidad de ejecución no es una consideración irrelevante a la hora de juzgar el grado de inteligencia de una actuación, la teoría de un programa de IA no es totalmente independiente de su implementación de programación. Seguramente no es irrelevante que la mayoría de los programas de IA estén escritos en algún tipo de lenguaje de procesamiento de listas, y que los procesos en la mayoría de ellos se implementen como producciones.

Una forma de aclarar el contenido sustantivo de nuestros programas es indicar con la mayor claridad posible las primitivas del dominio, que pueden distinguirse de las primitivas del lenguaje de programación. Sin embargo, esta distinción no siempre es fácil de hacer.

Más allá de los sentimientos pragmáticos que acabo de expresar, las relaciones entre la inteligencia, por un lado, y el tratamiento de las listas y las producciones, por otro, quizás no se han dilucidado adecuadamente. Se podría incluso reforzar la definición de un sistema de símbolos físicos para incluir un requisito de capacidades de procesamiento de listas, especialmente la capacidad de formar asociaciones y asociaciones etiquetadas (descripciones), así como la capacidad de actuar sobre el reconocimiento (producciones). Casi todos los programas inteligentes hacen un uso esencial de estas capacidades.

Al describir los programas inteligentes y aquellos de sus componentes que son de interés teórico, normalmente podemos caracterizar estos componentes de forma cualitativa, aunque inexacta. Esto nos lleva de nuevo a las leyes de la estructura cualitativa en la IA. Gran parte de nuestra comunicación sobre nuestras teorías adopta esta forma abreviada, preferiblemente respaldada por la moneda más dura de los programas en ejecución. Esta forma abreviada nos permite ignorar los detalles del programa que son irrelevantes para la teoría; no proporciona garantías de que el sistema descrito informalmente funcione como se anuncia.

Más adelante hablaré de los métodos para describir y evaluar programas. Pero antes de entrar en cuestiones de interpretación y evaluación, pasemos a la otra forma principal de teoría: las *Leyes de Estructura Cualitativa*.

## Leyes de Estructura Cualitativa en IA

Al tratar de desarrollar la Teoría en la Ciencia de la Computación, y específicamente en la IA, debemos buscar leyes de estructura cualitativa y regularidades de organización y proceso que las caractericen. Nuestra búsqueda será necesariamente empírica y experimental. En el caso de la IA, la búsqueda se llevará a cabo mediante el diseño de sistemas complejos que incorporen estas leyes (cuantificadas con valores de parámetros particulares, por supuesto) y su funcionamiento en una amplia gama de condiciones, utilizando una variedad de observaciones y mediciones para caracterizar su comportamiento.

En nuestro discurso de Turing, Newell y yo propusimos, además de la Hipótesis del Sistema de Símbolos Físicos, una segunda ley QS, la *Hipótesis de la Búsqueda Heurística* (HS):

!!!quote
   Los problemas se resuelven (cuando se requiere inteligencia para la solución) buscando selectivamente (heurísticamente) a través de un espacio del problema (es decir, una representación del problema).

### La Hipótesis de la Búsqueda Heurística

La hipótesis HS es casi tan amplia como la hipótesis PSS, e igualmente cualitativa. Sin embargo, es bastante poderosa en cuanto a lo que excluye. Niega que los problemas se resuelvan generalmente mediante una búsqueda exhaustiva a través de grandes espacios del problema, o sin la ayuda del conocimiento de la estructura del espacio del problema. Este conocimiento se utiliza convirtiéndolo en una heurística de control de la búsqueda.

La Hipótesis HS se ve aumentada por una serie de leyes QS más específicas que caracterizan algunas heurísticas de búsqueda relativamente generales y útiles, y por algunos principios de control de búsqueda eficaces. Con respecto a la heurística de búsqueda, hemos aprendido que procesos como el *ascenso de la colina* y el *análisis means-ends* proporcionan bases poderosas para la selectividad en muchos dominios de tareas, y sabemos mucho sobre las condiciones bajo las cuales heurísticas como éstas son o no son efectivas. A veces (por ejemplo, [9]), incluso somos capaces de caracterizar estas condiciones formalmente.

Por ejemplo, el *[ascenso de la colina](https://es.wikipedia.org/wiki/Algoritmo_hill_climbing)* es un método fiable sólo cuando los máximos locales son también máximos globales, y debe complementarse con otros criterios cuando no se cumple esta condición; el *análisis means-ends* sólo funciona si el espacio del problema es factorizable en un cierto sentido (cuando los operadores pueden ordenarse de forma que las diferencias eliminadas por los operadores de alta prioridad no sean restablecidas por los de baja prioridad [7, 19]).

Con respecto al control de la búsqueda, se han ideado heurísticas de propósito especial para clases particulares de dominios de tareas: por ejemplo, la *[búsqueda alfa-beta](https://es.wikipedia.org/wiki/Poda_alfa-beta)* para entornos de juegos. Los contrastes de rendimiento entre las estrategias *[depth-first](https://es.wikipedia.org/wiki/B%C3%BAsqueda_en_profundidad)*, *[breadth-first](https://es.wikipedia.org/wiki/B%C3%BAsqueda_en_anchura)* y *[best-first](https://en.wikipedia.org/wiki/Best-first_search)* se conocen bastante bien. La mayor parte de este conocimiento también adopta la forma de leyes QS, aunque hay algunos teoremas matemáticos dispersos en la literatura (por ejemplo, teoremas sobre la eficiencia del _[algoritmo de búsqueda A*](https://es.wikipedia.org/wiki/Algoritmo_de_b%C3%BAsqueda_A*)_, medida por la longitud del camino de la solución; sobre la eficiencia, medida por el esfuerzo de cálculo esperado, sobre los criterios para la búsqueda óptima del mejor primero [38]).

Veinte o más años de investigación sobre los sistemas expertos han dado lugar a una tercera ley QS muy general, la *Solución de Problemas por Reconocimiento* (REC):

!!!quote
   Los sistemas expertos resuelven los problemas que se presentan con frecuencia en gran medida mediante el proceso de reconocimiento.

Es decir, un sistema experto (informático o humano) posee un conjunto de producciones capaces de advertir pistas en los problemas cotidianos y, a partir de ahí, evocar los conocimientos almacenados en la memoria que son pertinentes para hacer frente a las situaciones marcadas por las pistas. El reconocimiento desempeña un papel central, por ejemplo, en el diagnóstico médico, ya sea humano o automatizado, y en el primer sistema experto, *DENDRAL*, que interpreta los datos del espectrógrafo de masas para dilucidar la estructura química [23].

Los procesos de reconocimiento se implementan, por ejemplo, en la red de discriminación de *EPAM* y en las [redes Rete](https://es.wikipedia.org/wiki/Algoritmo_Rete) de los lenguajes de sistemas de producción. El uso de procesos de reconocimiento permite al experto recurrir a grandes conjuntos de datos, lo que sugiere otra ley QS estrechamente relacionada, el *Principio del Conocimiento*:

!!!quote
   Un sistema muestra una comprensión y una acción inteligentes a un alto nivel de competencia principalmente debido al conocimiento específico que pueden aportar: los conceptos, hechos, representaciones, métodos, modelos, metáforas y heurística sobre su dominio de esfuerzo. (Lenat y Feigenbaum [22])

Estos ejemplos, y especialmente las leyes QS, PSS, HS y REC, muestran en qué medida nuestro conocimiento general sobre la resolución de problemas en la IA está integrado en leyes de estructura cualitativa que han sido inducidas a partir de sistemas expertos específicos modelados como programas de ordenador. Todos estos programas son PSS, y sus componentes que implementan la heurística HS y REC son fácilmente identificables. En comparación con las leyes de estructura cualitativa, los teoremas matemáticos que el campo ha creado hasta la fecha se desvanecen en la insignificancia.

El mismo panorama se presenta cuando nos dirigimos a otras subdisciplinas de la IA: *el aprendizaje*, por ejemplo. Se han construido varios sistemas que aprenden de sus propios esfuerzos de resolución de problemas, o de los esfuerzos exitosos de resolución de problemas de otros en forma de ejemplos trabajados de soluciones de problemas. Los *[Sistemas de Producción Adaptativa](https://www.ijcai.org/Proceedings/75/Papers/042.pdf)* de Waterman, Neves y otros [24,40], pertenecen a esta línea de trabajo, al igual que los sistemas de *[Aprendizaje Basados en Explicaciones](https://es.sunrisehotelobzor.com/951666-explanation-based-learning-RCMFQD)* de Mitchell, y los *[Procedimientos de Fragmentación](https://es.wikipediamarathi.com/188549-soar-cognitive-architecture-UXCZOB)* de Soar [25]. Lo que hemos aprendido sobre el aprendizaje a partir de la construcción de tales sistemas quizá se resuma mejor con la ley QS del *Aprendizaje a partir de Ejemplos* (*LE*):

!!!quote
   Si a un sistema de producción se le proporcionan ejemplos detallados de soluciones de problemas, que muestren los pasos intermedios, entonces se puede utilizar el análisis means-ends o algún método relacionado de atribución causal para crear automáticamente nuevas producciones capaces de resolver problemas del mismo tipo general.

En otro ámbito de la IA, más de tres décadas de experiencia en la construcción de sistemas para la traducción automática del lenguaje natural han producido un cuerpo sustancial de conocimientos sobre los requisitos de tales sistemas, incluida la ley QS:

!!!quote
   Una traducción satisfactoria del lenguaje natural requiere no sólo el conocimiento de un léxico y una sintaxis, sino también un cuerpo sustancial de conocimiento semántico que proporcione el contexto para resolver las ambigüedades.

Se pueden extraer ejemplos similares de leyes QS de otros dominios dentro de la IA. En este sentido, la IA se asemeja a la mayoría de las disciplinas científicas. En Biología, por ejemplo, el conocimiento empírico suele estar plasmado en descripciones de las estructuras y procesos de especies específicas de organismos, combinadas con leyes QS más generales que describen mecanismos generales (por ejemplo, el metabolismo, los procesos que conectan el ADN con las proteínas, las reacciones inmunitarias). Cada vez más, estos mecanismos se modelan simbólicamente con programas informáticos; y las simulaciones informáticas se comparan con los resultados de las manipulaciones experimentales.

## El tratamiento de la complejidad

En la actualidad, el tema de la complejidad suscita un gran interés, pero sigue existiendo la duda de qué puede decirse con sentido sobre la complejidad en toda su generalidad. Son más prometedoras las teorías que se ocupan de aspectos o formas particulares de la complejidad. La *[Teoría Matemática del Caos](https://es.wikipedia.org/wiki/Teor%C3%ADa_del_caos)* trata la complejidad de los sistemas dinámicos no lineales cuyo comportamiento a largo plazo es imprevisible. La *Teoría de Sistemas que poseen muchos componentes* que interactúan se ocupa de otra forma de complejidad. Las *Teorías de Complejidad Computacional* se ocupan de una tercera forma.

Así pues, aunque la *complejidad* desnuda puede ser una categoría demasiado amplia para sustentar teorías con un contenido considerable (como lo fueron los *Sistemas Generales*), se puede ser optimista sobre la posibilidad de construir teorías y descubrir estructuras QS que caractericen varios tipos de sistemas complejos. Permítanme ilustrar estas posibilidades sólo para dos aspectos de la complejidad que están estrechamente relacionados: la estructura jerárquica de los sistemas de muchos componentes y la serialidad y el paralelismo en los sistemas complejos.

### Jerarquía

Hace tiempo que se ha observado empíricamente que la mayoría de los sistemas multicomponentes -tanto los observados en la naturaleza como los ideados por el hombre- tienen una arquitectura jerárquica [36]. Es decir, vistos de arriba abajo, pueden dividirse en subsistemas que a su vez se dividen en subsubsistemas, y así sucesivamente, hasta llegar a un nivel de primitivos que no queremos o no podemos descomponer más. El primer mandamiento de la programación estructurada es respetar esta jerarquía trabajando de arriba a abajo. El segundo mandamiento es minimizar la interacción entre las diferentes subestructuras (¡no a los GOTOs!). El tercer mandamiento es hacer que cada nivel de la jerarquía sea insensible a la estructura de los niveles inferiores, de modo que los niveles contiguos sólo interactúen a través de entradas y salidas.

Parece que la programación estructurada ya fue inventada hace muchos eones por la Naturaleza, ya que estos mandamientos se cumplen bastante bien en la gran mayoría de los sistemas naturales. Los organismos están hechos de sistemas (digestivo, respiratorio, circulatorio, etc.); los sistemas están hechos de órganos, los órganos de tejidos, los tejidos de células, las células de orgánulos, los orgánulos de proteínas, las proteínas de aminoácidos, los aminoácidos de átomos, etc. A una escala aún más minúscula, pasamos por los núcleos atómicos hasta las partículas elementales, los quarks y, posiblemente, las cuerdas. En el otro extremo de la escala, el universo contiene galaxias, que contienen estrellas, que pueden tener sistemas planetarios.

La jerarquía produce varias leyes de estructura cualitativa, e incluso algunas generalizaciones matemáticas precisas. Un ejemplo de las primeras es una ley QS según la cual *los sistemas jerárquicos evolucionarán más rápidamente que los no jerárquicos*, y una ley según la cual *la dinámica a largo plazo de tales sistemas depende (aproximadamente) sólo de la estructura de nivel superior, mientras que la dinámica a corto plazo, de alta frecuencia, se determina casi independientemente dentro de cada subsistema*.

Una de las generalizaciones matemáticas es una formalización de esta última ley QS, y proporciona algoritmos para los cálculos [5, 36]. Estas leyes, tanto cualitativas como cuantitativas, están estrechamente relacionadas con los mandamientos de la programación estructurada mencionados anteriormente.

La jerarquía puede considerarse un poderoso antídoto contra la complejidad computacional. Es de esperar que la cantidad de cálculo necesaria para determinar el comportamiento (aproximado) de un sistema jerárquico sólo aumente linealmente con el número de primitivas; y si los subsistemas de cualquier nivel son y permanecen idénticos (por ejemplo, células idénticas en los tejidos de un organismo), que sólo aumente logarítmicamente.

Dado que las posibilidades de computación paralela en un sistema están inversamente relacionadas con el número y la fuerza de las restricciones de precedencia, y estas últimas están relacionadas con la intensidad y la frecuencia de la interacción de las partes, esperaríamos que la organización jerárquica favoreciera el paralelismo, siempre que las líneas de jerarquía se utilizaran para guiar los límites de los subsistemas paralelos. Es decir, esperaríamos obtener una capacidad de paralelismo entre componentes que no tienen una interacción de alta frecuencia.

Estas afirmaciones tendrían que ser mucho más precisas antes de poder tomarse al pie de la letra, pero ilustran una forma en la que se podría abordar el diseño de sistemas paralelos. Resulta interesante que principios como estos se den en la mayoría de las organizaciones humanas, que son casi siempre jerárquicas (no me refiero a la jerarquía de autoridad, sino a las disposiciones departamentales de cajas dentro de cajas), y con la jerarquía dispuesta de forma que las unidades más grandes tengan una ocasión relativamente infrecuente de interactuar entre sí.

Al igual que con los demás temas que hemos tratado, vemos que la investigación empírica tiene que desempeñar un papel importante en el estudio de la complejidad, pero que también hay lugar para la teoría matemática que, al menos, manejará modelos simplificados de los fenómenos reales complejos y dará orientación para la realización e interpretación de los experimentos. En gran medida, llegaremos a la comprensión de los sistemas complejos construyendo y probando los mismos.

## El papel de la teoría formal

Ya he hecho una serie de comentarios sobre el papel de las teorías formales en la Inteligencia Artificial, observando que los teoremas matemáticos precisos sólo han desempeñado un papel modesto en la IA, y es poco probable que desempeñen un papel central en un futuro previsible. Como en la mayoría de las demás ciencias empíricas, las teorías de mayor importancia e impacto han sido las leyes de estructura cualitativa, apoyadas por experimentos detallados y simulaciones.

Por otro lado, *teoremas matemáticos precisos* no es sinónimo de *teorías formales*. Los programas de ordenador cumplen las mismas normas de precisión que las expresiones simbólicas de otras partes de las matemáticas. Lo que los distingue de algunas matemáticas que se han aplicado a los problemas más sencillos de las Ciencias Físicas es que no suelen admitir soluciones en forma cerrada (es decir, teoremas). En consecuencia, como hemos visto, la principal técnica para extraer inferencias de ellos es ejecutarlos en entornos de tareas apropiados y evaluar su comportamiento.

Si pensamos en los teoremas y en la simulación simplemente como dos tipos de tratamiento formal, obtenemos los primeros cuando simplificamos y abstraemos el mundo real para adaptarlo a las herramientas matemáticas de que disponemos. Los segundos se obtienen cuando se tiene en cuenta una mayor complejidad del mundo. En la Informática en general, y en la IA en particular, solemos operar en áreas de mayor complejidad que aquellas en las que se pueden demostrar teoremas. Esto no es una virtud; es simplemente un hecho de la vida. Deberíamos atesorar las ocasiones en las que se pueden demostrar teoremas de cierta generalidad, potencia y relevancia.

### Condiciones iniciales y de contorno en los programas

Algunos se sienten incómodos porque los programas parecen mucho más complejos que las leyes del movimiento de Newton, o las ecuaciones de Maxwell, o incluso las leyes de la mecánica cuántica. Podemos tranquilizarnos con lo dicho anteriormente, que una parte sustancial de esta complejidad en los programas de IA se debe a que incorporan no sólo mecanismos generales básicos para realizar sus tareas, sino también una gran cantidad de conocimientos relativos a dominios de tareas particulares, y estrategias y heurísticas específicas de esos dominios. Los conocimientos y estrategias específicos de cada dominio se corresponden con las condiciones iniciales y de contorno de las teorías de otras ciencias.

### Primitivas de la teoría frente a detalles de programación

También he observado que incluso el código informático que representa este núcleo no señala dónde termina la teoría de la IA y dónde toma el relevo la pura conveniencia de la programación. Dónde está ese límite es una cuestión sustantiva, es decir, experimental.

### Lenguajes de Especificación para las teorías

Una forma diferente de aclarar las afirmaciones teóricas incluidas en los programas es definir lenguajes relativamente formales que no se implementan con tanta precisión como los lenguajes de programación, pero que describen la teoría de una forma que permite a cualquier experto en la materia programarla. Ejemplos de este método de generalización conservando una buena parte de la precisión se encuentran en los lenguajes utilizados en nuestro libro, *Scientific Discovery*, para describir el programa *BACON* y los otros programas de descubrimiento que allí se discuten; y en varios formalismos utilizados en *Human Problem Solving* para describir *GPS* y otros programas de resolución de problemas.

En la actualidad se están realizando algunos esfuerzos [4] para definir lenguajes de especificación estándar que podrían utilizarse para definir teorías de manera formal, sin necesidad de una implementación completa; pero queda por ver si un único lenguaje puede hacer el trabajo o si se necesitarán varios lenguajes para dar cabida a representaciones radicalmente diferentes utilizadas en el manejo de diferentes tareas cognitivas, o de las mismas tareas con diferentes estrategias.

Y, por último, los mecanismos que incorporan los programas suelen poder enunciarse de forma aún más sucinta, aunque menos precisa, como leyes de estructura cualitativa.

# Evaluación de los Sistemas Inteligentes

Evaluar el éxito de un esfuerzo de investigación en Inteligencia Artificial puede ser relativamente sencillo o puede ser complejo. Cuando *Logic Theorist* (*LT*) demostró que una búsqueda heurística bastante primitiva, con una modesta capacidad de selectividad, podía encontrar pruebas para muchos teoremas en *Principia*, una obra básica de Lógica, ese hecho por sí solo nos dijo mucho sobre la inteligencia. La importancia del resultado dependía de que la tarea no fuera trivial para los humanos. También dependía del hecho de que el programa requiriera cantidades modestas de cálculo (cantidades casi triviales según los estándares actuales), pero cantidades comparables a las que podríamos pensar que podría proporcionar un cerebro humano. Dependía del hecho de que la heurística de LT, aunque simple, hacía su búsqueda altamente selectiva en comparación con la búsqueda de fuerza bruta.

Se pueden hacer afirmaciones similares sobre sistemas de identificación de moléculas como *DENDRAL*, *SHRDLU* de Winograd, sistemas de diagnóstico médico como *[MYCIN](https://es.wikipedia.org/wiki/Mycin)* e *INTERNIST*, o sistemas de descubrimiento científico como *AM* y *BACON*. Lo que hace que estos sistemas sean centralmente interesantes para la IA es que realizan tareas que, en los humanos, requieren niveles profesionales de inteligencia y conocimiento, y al hacerlo, exhiben una combinación de base de conocimientos, potencia de cálculo y heurística suficiente para la tarea. Podemos hacernos eco de la afirmación de Samuel Johnson sobre el perro bailarín: *La maravilla no es que baile bien; la maravilla es que baile*. Demostrar el abanico de tareas que requieren inteligencia y que pueden programarse para los ordenadores y describir la naturaleza de estos programas son los principales objetivos de la IA. Cuando hablamos de evaluar dichos programas, nuestro principal objetivo debe ser comprenderlos.

## Los objetivos de la evaluación

La complejidad y dificultad de la evaluación de un sistema dependerá de nuestros objetivos. Como acabamos de ver, si nuestro propósito es avanzar en la teoría pura de la inteligencia, nuestro primer objetivo será construir sistemas que ejemplifiquen la inteligencia de diferentes formas en diferentes entornos de tareas. Evaluar si hacen lo que esperamos que hagan puede ser relativamente sencillo. Pero hay otras ocasiones en las que la evaluación debe ser más elaborada y basada en principios.

### Simulación de la inteligencia humana

Cuando nuestro interés radica en comprender los procesos mentales humanos, demostrar que los programas pueden realizar tareas de las que son capaces los profesionales humanos es sólo el primer paso. Si queremos afirmar que *BACON* nos enseña algo sobre la forma en que los científicos humanos hacen descubrimientos, también debemos comparar los procesos de *BACON* con datos, de campo o de historia o de laboratorio, que describan los procesos realmente utilizados por los científicos.

### Diseño de sistemas expertos

Cuando el interés radica en crear sistemas expertos, como *DENDRAL* o *MYCIN*, que puedan complementar, suplir o sustituir las actividades de los expertos humanos, los mecanismos empleados y las medidas de éxito vuelven a cambiar. Al construir sistemas expertos, los procesos utilizados por nuestros sistemas no se limitarán a los procesos humanos, sino que tendremos que comparar la calidad de las actuaciones de los programas con las actuaciones humanas, y con las actuaciones de otros sistemas expertos en el mismo dominio, en todas las dimensiones de interés: por ejemplo, la calidad de las soluciones, la tasa de error, el coste, la facilidad de uso, etc.

### Ampliación de la teoría

En los dos casos que acabamos de mencionar, la síntesis de sistemas va más allá del mero diseño y evaluación de sistemas específicos para usos concretos. Existe un interés por mejorar los diseños (o las simulaciones). La investigación incluye la determinación de las características que deben tener los sistemas y los principios generales que deben incorporar para que puedan realizar sus tareas y llevarlas a cabo con eficacia.

Así, en el ámbito de la Inteligencia Artificial, necesitamos teorías sobre las características y los principios subyacentes de los sistemas capaces de retener la información en la memoria y recuperarla cuando sea necesario, y teorías sobre los sistemas de resolución de problemas, los sistemas de inducción de conceptos, los sistemas de aprendizaje, los sistemas de navegación y operación en el mundo exterior (robots), los sistemas de comprensión del habla humana, etc. Cuanto más potentes sean estas teorías, más podremos anticipar las propiedades que deben poseer los sistemas de estos dominios para exhibir inteligencia (humanoide o de otro tipo), y mejores serán los sistemas que podamos diseñar. 

### Mejorar el proceso de diseño

Además, la investigación puede tener como objetivo mejorar la eficacia de los propios procesos de diseño y evaluación. Dado que el diseño y la evaluación son procesos inteligentes y, por tanto, entran en el ámbito de la Inteligencia Artificial y de la Hipótesis PSS, este tipo de investigación no es distinta de la mencionada anteriormente. De hecho, la *Teoría del Diseño* puede considerarse una parte especial de la *Teoría de Resolución de Problemas*. Se puede estudiar creando y estudiando sistemas de diseño automático.

## Evaluación de los diseños de Sistemas Expertos

En el caso de los sistemas expertos, la evaluación de un determinado diseño suele ser muy pragmática: ¿El nuevo sistema funciona mejor y/o más eficazmente que los sistemas ya disponibles? Cuanto mayor sea la superioridad, más fácil será demostrarla. De forma análoga, aunque se publicaron estadísticas sobre la rapidez con la que los primeros ordenadores de la década de 1940 realizaban determinados cálculos, la noticia más importante era que los realizaban. Esta información era suficiente para apoyar su desarrollo. Lo mismo ha ocurrido con las máquinas de vapor, los automóviles, los aviones, las radios y todas las demás innovaciones importantes de la Ingeniería.

Esto no quiere decir que la evaluación no sea importante para el avance de la tecnología, sino que en las fronteras de una nueva tecnología, una evaluación cualitativa muy cruda puede ser suficiente para señalar el camino. El proceso de diseño, con su constante modificación del sistema emergente para hacer frente a las dificultades y fallos de funcionamiento, incorpora en sí mismo un severo régimen de evaluación. Además, las consideraciones de extensibilidad, visibles para los diseñadores que están familiarizados con los detalles del diseño, pero que no se revelan en el rendimiento de los primeros diseños, pueden ser más importantes a la hora de señalar direcciones fructíferas para la I+D que las estadísticas de rendimiento.

Nos encontramos ante la célebre receta del guiso de conejo, que comienza: *Primero cazar el conejo*. Primero hay que diseñar un sistema que tenga la capacidad general deseada, al menos a un nivel mínimo. Una vez logrado esto, la mejora del diseño y la evaluación final pueden ser muy difíciles, pero al menos se tiene una base sobre la que proceder.

A veces, el objetivo inmediato de la investigación es construir un sistema que tenga un uso práctico. Más a menudo, el objetivo es utilizar el diseño y la evaluación como base para construir teorías de IA de los tipos sugeridos en las secciones anteriores. Las tareas se seleccionan por su viabilidad y por la luz que pueden arrojar sobre los principios generales de organización y funcionamiento de los sistemas inteligentes, allanando el camino para la construcción en una fecha posterior de sistemas que tengan utilidad en el mundo real.

Al principio, se seleccionaron tareas relativamente sencillas y bien estructuradas, que requerían pocos conocimientos del mundo real. Entornos estándar como el ajedrez, la Torre de Hanoi y el Mundo de Bloques nos proporcionaban situaciones en las que podíamos experimentar y llegar a comprender las propiedades y el funcionamiento de los mecanismos fundamentales de resolución de problemas.

Con el creciente éxito en el diseño de estos sistemas (y el aumento del tamaño y la velocidad de los ordenadores disponibles para la simulación), la investigación se extendió gradualmente a tareas que requerían grandes cantidades de conocimiento del mundo real y a tareas en las que los objetivos y las restricciones iniciales estaban menos definidos: interpretación de espectrogramas de masas, diagnóstico de enfermedades. Nos han enseñado, entre otras cosas, cómo debe organizarse el conocimiento en la memoria y procesarse para permitir una respuesta inteligente a entornos de tareas ricos en conocimiento.

Las tareas robóticas, es decir, aquellas en las que un sistema debe enfrentarse a un entorno real, son cada vez más importantes para la investigación de la IA, ya que obligan a prestar atención a los tipos y niveles de complejidad e incertidumbre que se pueden perfeccionar en los bancos de prueba de laboratorio. (Lo que llamo *robótica* no se limita a las tareas que exigen una respuesta sensorial y física; un sistema de programación que gestiona un flujo real de pedidos de fábrica y responde a la información genuina sobre la finalización, los tiempos de inactividad de la máquina, las cancelaciones, los errores de datos, etc., también es un *robot* para estos fines).

A estas alturas, se ha explorado una amplia gama de tareas, incluidas muchas que, cuando las realizan los seres humanos, exigen una experiencia de nivel profesional, un aprendizaje e incluso esas cualidades que llamamos *intuición*, *perspicacia* o *creatividad*. ¿Cuáles de estos tipos de tareas de referencia y bancos de prueba son los más prometedores para la futura investigación en IA? Sólo puedo responder: *Todo lo anterior*. Un artículo publicado recientemente en la revista *AI Magazine* [15] ofrece un debate muy reflexivo sobre estas cuestiones y, especialmente cuando los autores revelan sus desacuerdos junto con sus puntos de acuerdo, ilustra claramente la complementariedad de los diferentes tipos de bancos de prueba para la IA. Si tuviera que expresar una preferencia, apoyaría en general las observaciones de Steve Hanks sobre *los peligros de la experimentación en lo pequeño*, no porque piense que dicha experimentación es innecesaria, sino porque su manejabilidad y limpieza a veces nos seduce para que descuidemos dominios de complejidad del mundo real, y nos neguemos a enfrentarnos directamente a las cuestiones de extensibilidad.

¿Qué es un éxito y qué un fracaso en el diseño de sistemas expertos? Se han evocado tres tipos de criterios: la comparación con el rendimiento humano, la medición del rendimiento en un conjunto estándar de tareas del dominio de interés y la comparación con un límite superior de rendimiento determinado teóricamente. Pero antes de abordar estas posibles soluciones al problema de la evaluación, debemos decir algo sobre lo que entendemos por un Sistema Experto *bueno* o *eficaz*.

### Dimensiones de la eficacia

Se nos ocurren inmediatamente tres dimensiones de la eficacia: la *calidad del rendimiento*, el *alcance y la flexibilidad*, y la *eficiencia computacional*. Podemos juzgar un programa de ajedrez, por ejemplo, a lo largo de la primera y tercera dimensiones por su fuerza de juego y por el tiempo que tarda en hacer una jugada. Por supuesto, a menudo habrá un equilibrio entre estos dos criterios. Con respecto al alcance y la flexibilidad, un programa para jugar al ajedrez no sirve para otras tareas, mientras que el solucionador general de problemas puede intentar cualquier tarea para la que se pueda idear una representación adecuada y una tabla de conexiones entre operadores y diferencias. La *calidad del rendimiento* es en sí misma un criterio multidimensional, que puede incluir componentes como la *fiabilidad*, la *degradación gradual*, la *facilidad de uso* y otros.

### Comparaciones con el rendimiento humano

En cuanto se demostró que se podía invertir una gran matriz más rápidamente con un ordenador digital que con una calculadora de mesa, la gente empezó a hacerlo. En muy poco tiempo, el ordenador era tanto más potente que la calculadora, incluso en términos económicos, que no fue necesario realizar una evaluación sofisticada para demostrar la superioridad. Lo mismo puede decirse, en general, de los sistemas expertos con más sabor a IA que los utilizados para la inversión de matrices.

Los niveles de rendimiento humano proporcionan puntos de referencia útiles para medir la calidad de los sistemas expertos, siempre que el rendimiento del sistema se encuentre dentro del rango humano. El rendimiento humano no sólo proporciona una métrica a través de ese rango, sino que también calibra la amplitud y la flexibilidad del rendimiento del sistema en diversas tareas. Estas medidas pueden utilizarse tanto si el sistema experto imita los procesos humanos como si no.

### Comparación en tareas estándar

Es conveniente disponer de un conjunto de tareas estándar de referencia muestreadas de alguna manera de la población de tareas de un dominio [12, 33]. Las tareas estándar pueden utilizarse para evaluar un sistema en distintas fases de su desarrollo y, sobre todo, para comparar la potencia de los sistemas competidores. La dificultad reside en definir un estándar adecuado.

Supongamos que queremos evaluar un sistema de diagnóstico médico. (Para un excelente ejemplo reciente, véase la evaluación del sistema *QMR* de N.B. Giuse, et al. [13]). Podríamos enumerar las enfermedades para las que queremos que el sistema funcione. Pero los síntomas que señalan la presencia de estas enfermedades son muy variables. Nuestra muestra de tareas tiene que ser una muestra no sólo sobre las enfermedades, sino sobre los patrones de síntomas, incluidos los patrones en los que se presentan varias dolencias simultáneamente. ¿Debemos ponderar nuestra muestra por las frecuencias de los patrones de síntomas en la población humana? ¿Debemos ponderarla por la gravedad de las enfermedades que señalan los síntomas? Algunas de estas preguntas podrían responderse, al menos en principio, utilizando un enfoque teórico de la decisión para el problema del muestreo.

Pero quizá estemos complicando el problema más de lo que realmente es. Para muchos fines prácticos, podemos suponer que cualquier muestra relativamente amplia clasificará los diferentes sistemas expertos más o menos en el mismo orden que cualquier otra muestra amplia. En el mejor de los casos, esto sólo será aproximadamente cierto y sólo es útil si nuestro principal interés es llegar a esa clasificación. Si queremos utilizar las tareas de prueba como guía para la mejora del sistema, su carácter inclusivo y la posibilidad de relacionar sus componentes con componentes específicos del sistema pueden ser más importantes que su representatividad.

Con todas estas salvedades, los conjuntos de tareas estándar pueden proporcionar, en general, puntos de referencia útiles para evaluar el rendimiento de los sistemas expertos y para comparar diferentes sistemas. Un buen ejemplo es el conjunto de pruebas que *ARPA* estableció en varias ocasiones para la evaluación de los sistemas de reconocimiento del habla [26]. Se probaron diferentes sistemas con el mismo corpus de voz y se evaluaron tanto la velocidad como la precisión. Dichas pruebas pueden diseñarse para evaluar en rangos específicos de vocabulario y materia.

Del mismo modo, los programas de ajedrez se evalúan de forma rutinaria mediante la competición entre programas y con jugadores humanos, y su fuerza se especifica mediante calificaciones *ELO*, utilizando la misma escala que se utiliza para calificar a los jugadores de ajedrez humanos.

A veces se han planteado objeciones a este tipo de *carreras de caballos* por considerar que desvían la atención de los principios científicos subyacentes a meras formas de *ganar*. Pero las objeciones carecen de fuerza, ya que ganar significa demostrar un sistema potente, y las pruebas de eficacia proporcionan una rica información no sólo sobre quién es más fuerte, sino también sobre los puntos fuertes y débiles específicos de los diseños, el mismo tipo de información empírica que conduce a la comprensión. Estos concursos disuaden a los proyectos de buscar bajo las farolas, donde es más fácil encontrar cosas, por muy irrelevantes que sean los descubrimientos para el objetivo.

### Límites teóricos del rendimiento

Las Teorías de la Complejidad Computacional nos han proporcionado algunos límites teóricos sobre el rendimiento del sistema. Una desventaja de las teorías existentes es que la mayoría de ellas se han centrado en criterios que facilitan la demostración de teoremas matemáticos sobre la complejidad, y estos pueden no ser los criterios que utilizaríamos para evaluar nuestros sistemas. Otro caso es el de la farola.

El criterio sobre el que ha sido más fácil demostrar teoremas es el rendimiento en el peor de los casos en el límite, cuando alguna medida del tamaño del problema, $N$, crece indefinidamente. Según este criterio, un sistema cuyo tiempo de cálculo esperado en el peor de los casos crece exponencialmente con $N$ es inferior a otro cuyo tiempo sólo crece polinomialmente con $N$. Además, cualquier sistema que no garantice la completitud (alcanzar una solución para cada problema en un tiempo finito) falla automáticamente la prueba del peor de los casos.

Seguramente preferiríamos medir la calidad por los tiempos de cálculo esperados en lugar de por los tiempos en el peor de los casos, pero para determinar los primeros, tenemos que definir una medida de probabilidad sobre la población de problemas. Por ello, y por otras razones de viabilidad matemática, rara vez se ha podido estimar los tiempos de cálculo esperados, y la mayoría de los teoremas existentes utilizan el criterio del peor caso.

Uno de los pioneros de la teoría de la complejidad, Michael Rabin, ya describió en 1974 [32] el dilema que acabo de presentar, expresó su insatisfacción con los límites de la teoría existente y ofreció algunas sugerencias para remediarlo (incluyendo la definición de algoritmos de aplicabilidad limitada y permitiendo el cálculo con errores ocasionales). Lo que no sugirió, y lo que yo ofrecería como solución para el dilema, es la idea de utilizar criterios empíricos, basados en la experiencia computacional real, de *lo que funciona*, en aquellos casos habituales en los que los teoremas del tipo deseado no están disponibles. Esto es, de hecho, lo que tanto la IA como la computación numérica han hecho desde el principio.

Para muchos propósitos, preferiremos utilizar sistemas computacionales que, aunque a veces no resuelvan los problemas, suelen hacerlo en poco tiempo y resuelven una gran fracción de los problemas presentados en un tiempo aceptable (aunque no siempre corto). Supongamos hipotéticamente algunas de las formas alternativas en las que podríamos querer evaluar los sistemas: imaginemos un sistema A que resuelve el 60% de los problemas que se le presentan en 1 minuto, pero parece alcanzar la asíntota después de una hora con sólo el 7,5% del total resuelto; un sistema B que alcanza el 60% sólo después de 30 minutos, pero resuelve el 75% con una hora, y parece alcanzar la asíntota por encima del 90%; y por último, un sistema C que garantiza la resolución de todos los problemas antes o después, pero sólo resuelve el 10% en 30 minutos, y el 20% en dos horas. No es evidente cuál de estos sistemas es preferible, y la preferencia dependerá de los costes de computación y de la gravedad de las consecuencias de no resolver un problema en un tiempo de computación determinado. Cuando los problemas que hay que resolver son muy grandes en comparación con nuestros recursos informáticos, rara vez querremos clasificar los sistemas alternativos según el tiempo que les llevará resolver cada problema.

Debido a la relativamente escasa correspondencia entre la trazabilidad matemática de los criterios de evaluación de los programas, por un lado, y la importancia práctica de los criterios, por otro, las teorías matemáticas no nos han llevado muy lejos en la evaluación de sistemas, y tenemos que confiar principalmente en los métodos de evaluación empírica para guiar el diseño.

La cuestión de la escalabilidad de un diseño está estrechamente relacionada con los problemas de complejidad computacional. Los diseños que funcionan bien a pequeña escala no siempre lo hacen. En este caso, dado que los algoritmos que son exponenciales en el tamaño del problema explotan rápidamente, las medidas estándar de complejidad computacional pueden ser de cierto valor. Sin embargo, la cuestión práctica no es cómo escalan los sistemas en el límite, sino qué cálculo requieren cuando se utilizan en problemas de los tamaños que se dan en la práctica. No es especialmente interesante saber si un programa de procesamiento del lenguaje natural puede manejar un vocabulario de diez mil millones de palabras; suele ser mucho más interesante saber si puede manejar un vocabulario de cien mil palabras (o, para algunas aplicaciones, incluso de 100 palabras).

Los sistemas también pueden evaluarse en función de la bondad de la solución. En investigación operativa (programación lineal, programación entera, etc.) existe la tradición de evaluar la eficiencia de un programa por los tiempos que requiere para alcanzar soluciones óptimas, pero en muchas situaciones podríamos preferir un sistema que normalmente alcanzara una solución muy buena (no necesariamente óptima) en poco tiempo a otro que encontrara el óptimo, pero sólo después de muchos cálculos. En los sistemas que tienen que responder en tiempo real, por ejemplo, el cálculo suele devolver la solución *mejor hasta el momento* cuando se alcanza el límite de tiempo, o una solución *satisfactoria* en cuanto se obtiene. Puede ser imposible, o simplemente un despilfarro, exprimir hasta la última gota de aproximación a la solución óptima.

También ha habido una tradición (por ejemplo, en relación con el algoritmo de búsqueda A*) de tratar de minimizar el número de pasos hasta la solución; mientras que en muchos dominios, el número de pasos hasta la solución es de poco interés; lo que se quiere es conservar el tiempo de cálculo necesario para encontrar la solución [38]. Si estamos demostrando teoremas difíciles, es más frecuente que nos fijemos el objetivo de encontrar una prueba que el de encontrar la prueba más corta. El camino más corto a la solución y el tiempo de cálculo esperado más corto a la solución son criterios completamente diferentes, y normalmente es este último, no el primero, el que es relevante.

## Uso de pruebas estadísticas en la evolución

En la literatura de la IA se han utilizado muy poco los métodos estadísticos estándar para comprobar las hipótesis. Se puede argumentar a ambos lados de la cuestión de si esto es desafortunado o afortunado. Debo confesar que tengo algunas actitudes bastante fuertes al respecto, formadas en el curso de una larga experiencia con la teoría de pruebas de hipótesis, como usuario y observador del uso típico y, a veces, como contribuyente a la teoría. Sólo puedo ofrecer aquí un breve resumen de estas opiniones, con algunas referencias a la literatura publicada.

Las pruebas de significación estadística se utilizan mucho en Psicología y Biología, pero muy poco en Física (los clásicos *errores probables* de la Física suelen ser estimaciones de la precisión de los instrumentos, no pruebas de la probabilidad de que un fenómeno observado haya podido ocurrir por azar). Las pruebas de significación se utilizan legítimamente para comprobar si una variable produce algún efecto (en comparación con la hipótesis nula de que el *efecto* observado se produjo por azar). La presencia o ausencia de significación estadística no dice nada en absoluto de si el efecto es importante en magnitud: significación e importancia son magnitudes no relacionadas.

Como coinciden unánimemente los estadísticos matemáticos, las pruebas de significación estadística no pueden utilizarse para comprobar si un modelo se ajusta a los datos (para una breve explicación de por qué no pueden, véase [14] o [35] y las referencias allí citadas). Una alternativa adecuada para informar de dichas pruebas es informar del porcentaje de varianza explicada (R*). Además, los coeficientes de regresión (no los coeficientes de correlación), que muestran cuánto cambia una variable dependiente con el cambio de una independiente, proporcionan medidas de la importancia de la variable independiente. Incluso esta última afirmación sólo es válida si las ecuaciones que se analizan son ecuaciones estructurales, que reflejan la estructura causal subyacente de los fenómenos [17].

Como la IA se ocupa principalmente de evaluar sistemas (es decir, modelos), es poco probable que las pruebas estadísticas de hipótesis desempeñen un papel muy útil en la empresa, aunque sería muy deseable que se prestara más atención a la medición de la magnitud, y por tanto de la importancia, de los efectos producidos por los cambios en los sistemas que operan en determinados tipos de entornos.

# Teorías de la inteligencia humana

A lo largo de este documento he hecho hincapié en la dirección de la investigación sobre IA que se ocupa de la teoría general de la inteligencia, y no he tenido mucho que decir sobre los modelos de los procesos cognitivos humanos: los modelos psicológicos.

A pesar de compartir el método de investigación, el diseño y la evaluación de sistemas, no hay ninguna razón inmediatamente obvia por la que deba haber una conexión estrecha entre la investigación dirigida al diseño de sistemas inteligentes y la simulación de la cognición humana, o entre las correspondientes teorías de la inteligencia. Podría ser que, debido a las diferencias radicales entre los dispositivos electrónicos y los cerebros, los programas diseñados para ser sistemas expertos eficientes fueran totalmente diferentes en arquitectura y proceso de los sistemas diseñados para simular el pensamiento humano.

Hasta cierto punto, esto es así. Los programas de ajedrez más potentes (diseñados específicamente como sistemas expertos) no juegan al ajedrez del mismo modo que los grandes maestros humanos. Sus búsquedas para resolver problemas son mucho más amplias y mucho menos selectivas que las búsquedas de los maestros de ajedrez humanos [39]. Sin embargo, se han escrito algunos programas de ajedrez de otro tipo (por ejemplo, el programa *NSS*, *MATER*, *PARADISE*) con el objetivo de entender el juego humano imitándolo.

Desde 1993, los programas más potentes diseñados como sistemas expertos juegan al ajedrez a un formidable nivel de gran maestro, mientras que los programas más potentes diseñados como simulaciones cognitivas son modestos aficionados. Los programas diseñados como sistemas expertos realizan enormes búsquedas, mucho más allá de las capacidades humanas, antes de realizar sus jugadas, y generalmente sólo hacen uso de un almacén moderado de conocimientos de ajedrez. Las simulaciones cognitivas exploran sólo unas pocas (tal vez cientos, pero no millones) de las ramas del árbol de la partida y hacen uso de conocimientos heurísticos de ajedrez para seleccionar las ramas a explorar.

Pero la cuestión tiene otra cara. Aunque los sistemas expertos y las simulaciones cognitivas están sujetos a restricciones internas muy diferentes (la física de los ordenadores frente a la biología de los cerebros), cuando realizan las mismas tareas están sujetos a las mismas restricciones externas, las mismas exigencias de la tarea. En la medida en que las exigencias de las tareas son numerosas y pesadas, estas exigencias pueden revelarse en similitudes fundamentales entre los programas que las realizan, por muy disímiles que sean los medios de implementación en el nivel más bajo del hardware: las restricciones internas.

Los programas construidos para simular el comportamiento humano se evalúan de forma diferente a los programas construidos simplemente para realizar de forma eficiente tareas que requieren inteligencia. Los primeros se ponen a prueba comparando su comportamiento con el de los seres humanos en los mismos entornos de tareas, exactamente como se pone a prueba cualquier teoría cuya función sea describir y explicar fenómenos empíricos en algún dominio.

No hay nada en la metodología que la distinga a nivel general de la metodología de cualquier ciencia empírica. El paradigma general consiste en utilizar la teoría para predecir los fenómenos empíricos, observar los fenómenos, comparar las predicciones con las observaciones y revisar la teoría para que concuerde mejor con los datos. Como hay una gran literatura sustantiva sobre los modelos simbólicos de la cognición (por ejemplo, [1, 28]) así como una literatura sobre la metodología (por ejemplo, [6, 25]), no discutiré más el tema aquí.

# El futuro de la Inteligencia Artificial

Al principio de mis comentarios, dije que iba a prescribir el futuro de la IA sobre la base de lo que nos ha enseñado el pasado. Una serie de lecciones importantes del pasado deberían ser ahora razonablemente claras, y sólo necesito resumirlas brevemente.

## La estrategia fundamental: empujar la frontera

Nuestra principal tarea en la IA sigue siendo explorar una gama cada vez más amplia de actividades para cuyo desempeño es esencial la inteligencia. Tenemos que identificar los aspectos de la inteligencia que aún no hemos conseguido manejar, y atacar cada uno de ellos por separado en cuanto tengamos alguna idea sobre cómo proceder. El ataque debe consistir, como en el pasado, en construir sistemas que realmente realicen las tareas y produzcan los fenómenos asociados a ellas. Tenemos que evaluar nuestros programas en cuanto a su eficacia, y en cuanto a su alcance y escalabilidad.

No es difícil identificar algunos dominios de tareas que deberían ocupar un lugar destacado en la lista de prioridades, aunque no se puede afirmar que dicha lista sea completa. Mis propios candidatos serían dos que ya están recibiendo una atención considerable, y otro que todavía está bastante en la frontera. Estos tres candidatos son: el *aprendizaje automático*, la *robótica* y la *representación* (incluido el cambio de representación).

### Aprendizaje automático

El aprendizaje automático se encuentra en un estado de actividad vigoroso, con su propia revista y especialistas dentro de la IA. Mejor decir *especialistas, por desgracia*, pues existe el peligro de que la especialización retrase el impacto de los nuevos descubrimientos sobre los mecanismos de aprendizaje en la corriente principal de la IA. Se están explorando tanto las técnicas de aprendizaje en serie como las conexionistas, una sana competencia que nos enseñará en qué dominios es eficaz cada una.

Ha habido algunos logros en la teoría -en particular, teoremas sobre la convergencia de los algoritmos de aprendizaje-, pero lo que he dicho sobre los teoremas y las teorías en el cuerpo de mi documento es tan aplicable al aprendizaje como a otros temas de la IA. La ejecución de programas y su evaluación, y las leyes QS son la clave del progreso. Pat Langley (comunicación personal) cree que actualmente existe un equilibrio razonable entre el trabajo empírico y la teoría en el aprendizaje automático. Un recuento de las ponencias presentadas en una reciente conferencia sobre aprendizaje automático mostró que, de 44 ponencias, 39 contenían evaluaciones experimentales de programas específicos con medidas explícitas de rendimiento. Por otro lado, las conferencias sobre Teoría del Aprendizaje Computacional, probablemente pobladas más por informáticos de la teoría que por especialistas en inteligencia artificial, presentan principalmente trabajos teóricos.

### Robótica

La robótica también es un campo vigoroso, y también corre el peligro de estar demasiado separada de la corriente principal de la IA. Veo con sentimientos encontrados la creación de un programa de posgrado separado en robótica en mi propia universidad. Una de las críticas más comunes a la investigación sobre IA es que, al modelar situaciones problemáticas, no se distingue entre la situación real y el modelo de la situación almacenado en la memoria del ordenador. Como la robótica no puede permitirse el lujo de confundir el modelo con la realidad externa, debe incorporar en sus sistemas canales de retroalimentación que puedan corregir los modelos periódicamente para reflejar la realidad con mayor precisión. Por supuesto, esta distinción puede lograrse en la modelización de la IA, manteniendo en la memoria tanto un modelo abstraído como un *mundo real* simulado, pero la virtud de la robótica es que convierte la distinción en una necesidad en lugar de una opción, y recuerda continuamente al constructor del sistema la complejidad del mundo real, el que está fuera del ordenador.

### Representación

Antes de que un ordenador pueda dar muestras de inteligencia en el manejo de cualquier tarea, se le debe proporcionar una representación del dominio de la tarea: un espacio de problemas que especifique los tipos de objetos y fenómenos en los estados del problema, y los tipos de operadores que están disponibles para cambiar un estado del problema a otro. Se ha hecho algún trabajo, pero sólo una cantidad modesta, para mostrar cómo se pueden generar representaciones de problemas a partir de información externa.

El programa *UNDERSTAND* [16], por ejemplo, puede generar representaciones de problemas adecuadas como entradas para el *GPS* a partir de descripciones verbales de problemas (rompecabezas simples). El programa *ISAAC* [29] puede generar representaciones para problemas específicos de física a partir de descripciones en lenguaje natural de libros de texto. El programa *Soar* de Newell, Laird y Rosenbloom [25], tiene cierta capacidad para modificar sus representaciones a medida que se mueve a nuevos espacios de problemas. Korf [19] especificó algunos procedimientos para el cambio de representación en una clase restringida de problemas abstractos. Kaplan y Simon [18] han propuesto un método que produciría el cambio crítico de representación necesario para resolver el problema del *Tablero de Ajedrez Mutilado*.

Esta muestra de lo que se ha hecho nos recuerda lo mucho que queda por hacer. ¿Cómo sería un programa que pudiera inventar el cálculo, o incluso uno que pudiera seleccionar el cálculo como la representación adecuada para tratar un problema concreto? ¿A través de qué secuencia de pasos se obtuvo la representación matricial de Heisenberg para la Mecánica Cuántica, o la representación ondulatoria de Schrödinger?

En el nivel más general, el tema de la representación nos lleva a considerar las diferencias entre el razonamiento en palabras o en representaciones lingüísticas formales (Lógica, Matemáticas) y el razonamiento a partir de imágenes o diagramas. La comprensión de las propiedades de estas representaciones es una cuestión básica no sólo dentro de la IA, sino también en todo el ámbito de la interacción persona-ordenador.

## Metodología

Al argumentar que los avances pasados en IA proceden en gran medida de la construcción de programas inteligentes cada vez más sofisticados y complejos para realizar tareas cada vez más difíciles y mal estructuradas, no quisiera dejar la impresión de que la metodología que hemos utilizado ha sido intachable y que no se puede mejorar mucho en ella. Siempre que se pueda extraer una teoría de nuestros modelos y de los fenómenos que producen, deberíamos extraerla, al igual que se hace en otras ciencias empíricas. Pero quizá la mayor oportunidad de mejorar el método sea hacer que nuestros experimentos sean acumulativos (1) prestando una atención más sistemática y cuidadosa a la evaluación del sistema, y (2) prestando mucha más atención a la comparación entre sistemas como base para entender los mecanismos, y sus interacciones, que explican los resultados. Una vez más, al tratar estas cuestiones, me referiré principalmente al lado de la IA que corresponde a los Sistemas Expertos y no comentaré el lado psicológico, en el que la metodología ha alcanzado quizás un nivel de sofisticación algo mayor.

### Tareas estándar para la evaluación

Para evaluar los sistemas en varios dominios de tareas, necesitamos conjuntos de tareas estándar que serán utilizados repetidamente por muchos investigadores que estudian diferentes sistemas. Ya he mencionado los estándares que *DARPA* ha utilizado para evaluar los avances en la comprensión del habla. Podría ser una actividad muy apropiada para nuestra asociación profesional establecer, a través de comités, tales estándares para una serie de áreas. Esto no sólo crearía un consenso sobre los puntos de referencia para los investigadores, sino que también daría lugar a un valioso diálogo sobre lo que constituye un buen rendimiento: cómo dependen los criterios de la presencia o ausencia de restricciones en tiempo real en la computación, la relación entre los estándares de rendimiento y las teorías de la complejidad computacional, etc.

### Extracción de mecanismos y principios generales

El objetivo de la evaluación de los sistemas no es simplemente establecer cuál es el mejor en un momento dado, por muy interesantes que sean estas competiciones (como entre ordenadores de ajedrez). Dado que nombramos, y por lo tanto marcamos, nuestros sistemas, lo que solemos reportar en la literatura son comparaciones entre grandes sistemas complejos, cada uno de los cuales consta de un número considerable de mecanismos que interactúan. Después de saber que un sistema ha resuelto más problemas que otro, o que los ha resuelto más rápido, todavía no sabemos las razones de esa superioridad. Ni siquiera sabemos en qué aspectos utilizan mecanismos muy similares o muy diferentes para lograr sus resultados.

La comparación de sistemas no termina cuando hemos determinado cuál rinde más en determinados tipos de tareas. Eso es sólo el principio de la comparación de los mecanismos que emplea cada sistema y la contribución de estos mecanismos al rendimiento del sistema en diferentes tipos de tareas. Lo que buscamos, como siempre, son leyes QS que puedan guiar el diseño del siguiente sistema y que puedan hacer avanzar la teoría general de la inteligencia y los sistemas inteligentes.

Si, en mi relato del pasado y el futuro de la investigación en IA, he hecho hincapié en los métodos empíricos por encima de la teoría formal, es porque he percibido, en nuestras reuniones y en las páginas de nuestras revistas en los últimos años, una especie de envidia de la teoría que a veces sacrifica la atención a los problemas complejos pero reales en favor de la atención a los problemas demasiado simples que son susceptibles de un tratamiento matemático exacto. Algunos distinguidos miembros de nuestra profesión han llegado a cuestionar y degradar el propio concepto de *Informática Experimental*.

Mi propio historial científico está plagado de ejemplos de trabajos matemáticos, algunos de ellos relevantes para problemas reales, otros quizás no. La cuestión no es sustituir las Matemáticas por los experimentos, o viceversa; se trata de asegurar y mantener una tolerancia en toda nuestra disciplina para una pluralidad de enfoques de nuestros problemas científicos profundos; y una dedicación para mejorar cada uno de estos enfoques en sus propios términos.

(#) Agradecimientos

Esta investigación ha sido financiada por la *National Science Foundation*, subvención nº DBS-9121027; y por la *Defense Advanced Research Projects Agency*, Department of Defense, ARPA Order 3597, supervisada por el *Air Force Avionics Laboratory* bajo contrato F33615-81-K-1539. Se permite la reproducción total o parcial para cualquier propósito del Gobierno de los Estados Unidos. Aprobado para su publicación; distribución ilimitada.

(#) Referencias

[1] J .R. Anderson, The Archrrecture of (‘ogmtion (Harvard University Press, Cambridge, MA, 1083).

[2] R.A. Brooks, Intelligence without representation, Artif. Intell. 47 (19’31) 139-159.

[3] A.W. Burks, H.H. Goldstine and J. von Neumann. Preliminary Discussion of the Logical Design of an Electronic Computing Instrument (Institute for Advanced Study, Princeton. NJ, 1946).

[4] R. Cooper. J. Farringdon and J. Fox. Towards a systematic methodology for cognitive modelling, Unpublished manuscript.

[5] P.J. Courtois. Decomposability: Queuing and C‘omputer System Applications (Academic Press. New York, 1977).

[6] K.A. Ericsson and H.A. Simon. Protocol Analysis (MIT Press. Cambridge, MA, 1993).

[7] G.W. Ernst. Sufficiency conditions for the success of GPS, .I. ACM 16 (1969) 517-533.

[8] G.W. Ernst and A. Newell, GPS: A Case Study in Generality and Problem Solving (Academic Press, New York. 1960).

[9] O. Etzioni, Why PRODIGY/EBL works. in: Proceedings AAAI-90. Boston, MA (1990) 916-922.

[10] E.A. Feigenbaum and J.A. Feldman, Computers und Thought (McGraw-Hill, New York, 1963).

[11] E.A. Feigenbaum and H.A. Simon, EPAM-like models of recognition and learning, Cognitive SC;. 8 (1984) 305-336.

[12] J. Gaschnig. Performance measurement and analysis of certain search algorithms. Ph.D. Thesis, Department of Computer Science, Carnegie Mellon University, Pittsburgh, PA (l979).

[13] N.B. Giuse et al., Evaluating consensus among physicians in medical knowledge base construc- tion, Methods Inf. Med. 32 (1993) 137-145.

[14] L.W. Gregg and H.A. Simon, Process models and stochastic theories of simple concept formation, J. Math. Psychol. 4 (1967) 246-276.

[15] S. Hanks, M.E. Pollack and P.R. Cohen, Benchmarks, test beds, controlled experimentation. and the design of agent architectures. Al Mag. 14 (4) (1993) 17-42.

[16] J.R. Hayes and H.A. Simon, Understanding written problem instructions, in: L.W. Gregg, ed., Knowledge and Cognition (Erlbaum, Potomac. MD, 1974).

[17] W.C. Hood and T.C. Koopmans, eds., Studies in Econometric Method (Wiley, New York, 1953).

[18] C.A. Kaplan and H.A. Simon, In search of insight, Cognitive Psychol. 22 (1990) 374-419.

[19] R.E. Korf, Toward a model of representational changes, Artif. Intell. 14 (1980) 41-78.

[20] P. Langley and D. Kibler, The experimental study of machine learning, Unpublished Tech. Report. NASA Ames Research Center, Moffett Field, CA (1991).

[21] P. Langley, H.A. Simon, G.L. Bradshaw and J.M. Zytkow, Scientific Discovery (MIT Press, Cambridge, MA, 1987).

[22] D.B. Lenat and E.A. Feigenbaum, On the thresholds of knowledge, in: Proceedings IJCAI-87, Milan, Italy (1987) 1173-1182; also Artif. InteN. 47 (1991) 185-250.

[23] R.K. Lindsay, B.G. Buchanan, E.A. Feigenbaum and J. Lederberg, DENDRAL: a case study of the first expert system for scientific hypothesis formation, Artif. Intell. 61 (1993) 209-261.

[24] D.M. Neves, A computer program that learns algebraic procedures by examining examples and working problems in a textbook, in: Proceedings 2nd National Conference of the Canadian Society for Computational Studies of Intelligence, Toronto, Ont. (1978) 191-195.

[25] A. Newell, Unified Theories of Cognition (Harvard University Press, Cambridge, MA, 1990).

[26] A. Newell et al., Speech understanding systems: final report of a study group, Department of Computer Science, Carnegie Mellon University (1971).

[27] A. Newell, A.J. Perlis and H.A. Simon, What is computer science?. Science 157 (1967) 1373-1374.

[28] A. Newell and H.A. Simon, Computer science as empirical inquiry: symbols and search, Comm. ACM 19 (1976) 113-126.

[29] G.S. Novak, Representation of knowledge in a program for solving physics aproblems, in: Proceedings IJCAI-77, Cambridge, MA (1977) 286-291.

[30] D.A. Pomerleau, J. Gowdy and C.E. Thorpe, Combining artificial networks and symbolic processing for autonomous robot guidance, J. Eng. Appl. Artif. Intell. 4 (1991) 961-967.

[31] H. Pople, Problem solving: an exercise in synthetic reasoning, in: Proceedings IJCAI-77. Cambridge, MA (1977).

[32] M.O. Rabin, Theoretical impediments to artificial intelligence, in: Proceedings IFIPS Conference (1974).

[33] A.M. Segre, C. Elkan and A. Russell, Technical note: a critical look at experimental evaluations of EBL, Mach. Learning 6 (2) (1991) 183-196.

[34] L. Siklossy, Natural language learning by computer, in: H.A. Simon and L. Siklossy, eds., Representation and Meaning (Prentice-Hall, Englewood Cliffs, NJ, 1972).

[35] H.A. Simon, On judging the plausibility of theories, in: Van Roostelaar and Staal, eds., Logic, Methodology and Philosophy of Sciences III (North-Holland, Amsterdam, 1968).

[36] H.A. Simon, The Sciences of the Artificial (MIT Press, Cambridge, MA, 2nd ed., 1981).

[37] H.A. Simon, Cognitive architectures and rational analysis: comment, in: K. vanlehn, ed., Architectures for Intelligence (Lawrence Erlbaum, Hillsdale, NJ, 1991).

[38] H.A. Simon and J.B. Kadane, Optimal problem-solving search: all-or-none solutions, Artif. Intell. 6 (1975) 235-248.

[39] H.A. Simon and J. Schaeffer, The game of chess, in: R.J. Aumann and S. Hart, eds., Handbook of Game Theory (Elsevier, Amsterdam, 1992) 1-17.

[40] D. Waterman, Generalization learning techniques for automating the learning of heuristics, Artif. Intell. 1 (1970) 120-170.

[41] T. Winograd, Understanding Natural Language (Academic Press, New York, 1972).

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'short'};</script>
<!-- Markdeep: --><script src="markdeep.min.js?" charset="utf-8"></script>